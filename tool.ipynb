{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzt56B40085T",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data processing\n",
    "In this part we filtered out 15132 genes that are detected in less than 3 cells, and save it as whole data set((6648 cells, 17154 genes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 911
    },
    "id": "n7a5mbsGDJRi",
    "outputId": "95470b7a-5085-4f88-8701-e90bfff7d19f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install scanpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "sc.settings.verbosity = 3             # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xCQIX5QCoBB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "maledataRR = sc.read_mtx('male.mtx')\n",
    "femaledataRR = sc.read_mtx('female.mtx')\n",
    "fff=pd.read_csv('female.tsv',sep='\\t',header=None)\n",
    "mmm=pd.read_csv('male.tsv',sep='\\t',header=None)\n",
    "fff\n",
    "frames = [fff, mmm]\n",
    "name=pd.concat(frames,axis=0)\n",
    "femaledata=femaledataRR.T\n",
    "maledata=maledataRR.T\n",
    "femaledata.var.index = fff[1]\n",
    "maledata.var.index = mmm[1]\n",
    "femaledata.var\n",
    "femaledata.obs_names = [f\"Cell_{2685+i:d}\" for i in range(femaledata.n_obs)]\n",
    "maledata.obs_names = [f\"Cell_{i:d}\" for i in range(maledata.n_obs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "femaledata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maledataRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "femaledataRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyranges\n",
    "!pip install scanpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "neww=sc.read_h5ad(\"sex_chimeric_gender.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ids = neww.var['gene_ids'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.highest_expr_genes(neww, n_top=20)\n",
    "sc.pp.filter_genes(neww, min_cells=3)\n",
    "sc.pp.normalize_total(neww, target_sum=1e4)\n",
    "sc.pp.log1p(neww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.highest_expr_genes(neww, n_top=20)\n",
    "sc.pp.filter_genes(neww, min_cells=3)\n",
    "sc.pp.normalize_total(neww, target_sum=1e4)\n",
    "sc.pp.log1p(neww)\n",
    "matrix = neww.X.todense()# Your matrix data\n",
    "gene_ids = neww.var.index  # Your gene IDs\n",
    "\n",
    "# Create a DataFrame\n",
    "df_new = pd.DataFrame(matrix, columns=gene_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "adata = sc.read(\"sex_chimeric_gender_v2.h5ad\")\n",
    "\n",
    "# # Add sex prediction results to adata\n",
    "# file_path = '3.1_pred_new_sex.csv'\n",
    "# df = pd.read_csv(file_path)\n",
    "# adata.obs['pred_sex'] = df[\"0\"].values\n",
    "\n",
    "# # Assign 'female' or 'male' based on the prediction\n",
    "# adata.obs['pred_sex'] = adata.obs['pred_sex'].apply(lambda x: 'female' if x < 0.5 else 'male')\n",
    "\n",
    "# # Group and calculate the percentage\n",
    "# grouped = adata.obs.groupby(['conditions', 'pred_sex']).size().unstack(fill_value=0)\n",
    "# grouped['Total'] = grouped.sum(axis=1)\n",
    "# grouped_percentage = grouped.div(grouped['Total'], axis=0).drop(columns='Total') * 100\n",
    "# grouped_percentage.index = grouped_percentage.index.astype(str)\n",
    "# grouped_percentage = grouped_percentage.sort_index()\n",
    "\n",
    "# # Plotting\n",
    "# ax = grouped_percentage.plot(kind='barh', stacked=True, figsize=(10, 6))\n",
    "# ax.grid(False)\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# plt.xlabel('% Frequency of sex')\n",
    "# plt.ylabel('')\n",
    "# plt.title('Sex Distribution in each condition')\n",
    "# plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), frameon=False)\n",
    "# plt.tight_layout()\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.show()\n",
    "\n",
    "# # Display the percentage table\n",
    "# print(grouped_percentage)\n",
    "\n",
    "conditions = adata.obs['conditions'].unique()\n",
    "\n",
    "# Separating adata based on conditions\n",
    "# It's a good idea to check the actual condition values and modify as needed\n",
    "adata1 = adata[adata.obs['conditions'] == conditions[0], :]\n",
    "adata2 = adata[adata.obs['conditions'] == conditions[1], :]\n",
    "adata3 = adata[adata.obs['conditions'] == conditions[2], :]\n",
    "adata4 = adata[adata.obs['conditions'] == conditions[3], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Assuming adata1 is already defined and loaded\n",
    "\n",
    "# Plot the 20 highest expressed genes\n",
    "sc.pl.highest_expr_genes(adata1, n_top=20)\n",
    "\n",
    "# Filter out genes that are detected in fewer than 3 cells\n",
    "sc.pp.filter_genes(adata1, min_cells=3)\n",
    "\n",
    "# Normalize the data (scaling each cell to a total count of 1e4)\n",
    "sc.pp.normalize_total(adata1, target_sum=1e4)\n",
    "\n",
    "# Logarithmically scale the data\n",
    "sc.pp.log1p(adata1)\n",
    "\n",
    "# Convert the sparse matrix to a dense matrix and extract gene IDs\n",
    "matrix = adata1.X.todense()  # Your matrix data\n",
    "gene_ids = adata1.var.index  # Your gene IDs\n",
    "\n",
    "# Create a DataFrame\n",
    "df_adata1= pd.DataFrame(matrix, columns=gene_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Assuming adata2 is already defined and loaded\n",
    "\n",
    "# Plot the 20 highest expressed genes\n",
    "sc.pl.highest_expr_genes(adata2, n_top=20)\n",
    "\n",
    "# Filter out genes that are detected in fewer than 3 cells\n",
    "sc.pp.filter_genes(adata2, min_cells=3)\n",
    "\n",
    "# Normalize the data (scaling each cell to a total count of 1e4)\n",
    "sc.pp.normalize_total(adata2, target_sum=1e4)\n",
    "\n",
    "# Logarithmically scale the data\n",
    "sc.pp.log1p(adata2)\n",
    "\n",
    "# Convert the sparse matrix to a dense matrix and extract gene IDs\n",
    "matrix = adata2.X.todense()  # Your matrix data\n",
    "gene_ids = adata2.var.index  # Your gene IDs\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df_adata2= pd.DataFrame(matrix, columns=gene_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Assuming adata3 is already defined and loaded\n",
    "\n",
    "# Plot the 20 highest expressed genes\n",
    "sc.pl.highest_expr_genes(adata3, n_top=20)\n",
    "\n",
    "# Filter out genes that are detected in fewer than 3 cells\n",
    "sc.pp.filter_genes(adata3, min_cells=3)\n",
    "\n",
    "# Normalize the data (scaling each cell to a total count of 1e4)\n",
    "sc.pp.normalize_total(adata3, target_sum=1e4)\n",
    "\n",
    "# Logarithmically scale the data\n",
    "sc.pp.log1p(adata3)\n",
    "\n",
    "# Convert the sparse matrix to a dense matrix and extract gene IDs\n",
    "matrix = adata3.X.todense()  # Your matrix data\n",
    "gene_ids = adata3.var.index  # Your gene IDs\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df_adata3= pd.DataFrame(matrix, columns=gene_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Assuming adata1 is already defined and loaded\n",
    "\n",
    "# Plot the 20 highest expressed genes\n",
    "sc.pl.highest_expr_genes(adata4, n_top=20)\n",
    "\n",
    "# Filter out genes that are detected in fewer than 3 cells\n",
    "sc.pp.filter_genes(adata4, min_cells=3)\n",
    "\n",
    "# Normalize the data (scaling each cell to a total count of 1e4)\n",
    "sc.pp.normalize_total(adata4, target_sum=1e4)\n",
    "\n",
    "# Logarithmically scale the data\n",
    "sc.pp.log1p(adata4)\n",
    "\n",
    "# Convert the sparse matrix to a dense matrix and extract gene IDs\n",
    "matrix = adata4.X.todense()  # Your matrix data\n",
    "gene_ids = adata4.var.index  # Your gene IDs\n",
    "\n",
    "# Create a DataFrame\n",
    "df_adata4= pd.DataFrame(matrix, columns=gene_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df_new is your DataFrame\n",
    "\n",
    "# Randomly select 20 rows\n",
    "random_rows = df_new.sample(n=20, axis=0)\n",
    "\n",
    "# Randomly select 30 columns\n",
    "random_columns = random_rows.sample(n=30, axis=1)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(random_columns)\n",
    "\n",
    "# The resulting DataFrame after standardization\n",
    "new_df_htmap = pd.DataFrame(scaled_data, index=random_columns.index, columns=random_columns.columns)\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 8))  # Adjust the figure size as needed\n",
    "plt.imshow(new_df_htmap, cmap='viridis')\n",
    "\n",
    "# Save the figure as a JPEG file\n",
    "plt.savefig('heatmap.jpg', format='jpg', dpi=300)  # Adjust dpi for higher or lower resolution\n",
    "\n",
    "# Optionally, you can also display the plot if needed\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# And columns_to_extract is your list of column names\n",
    "columns_to_extract = ['Rpl35', 'Rps27rt', 'Rpl9-ps6', 'Rps27', 'Uba52', 'Lars2', 'Gm42418', 'Uty', 'Kdm5d', 'Eif2s3y', 'Ddx3y', 'Xist']\n",
    "\n",
    "columns_to_extract = [col for col in columns_to_extract if col in df_new.columns]\n",
    "extracted_columns = df_new[columns_to_extract]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "extracted_columns_1 = df_adata1[columns_to_extract]\n",
    "extracted_columns_2 = df_adata2[columns_to_extract]\n",
    "extracted_columns_3 = df_adata3[columns_to_extract]\n",
    "extracted_columns_4 =df_adata4[columns_to_extract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "extracted_columns_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "LYs1iAbq_9jJ",
    "outputId": "3e754f83-aacc-40ae-c0b9-bfb885b5039b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "maledata\n",
    "ct = np.random.choice([\"1\"], size=(maledata.n_obs,))\n",
    "maledata.obs[\"gender\"] = pd.Categorical(ct)  # Categoricals are preferred for efficiency\n",
    "maledata.obs\n",
    "femaledata\n",
    "ct = np.random.choice([\"0\"], size=(femaledata.n_obs,))\n",
    "femaledata.obs[\"gender\"] = pd.Categorical(ct)  # Categoricals are preferred for efficiency\n",
    "femaledata.obs\n",
    "\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEjfA0RCoLbZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import anndata\n",
    "fw=femaledata.X.todense()\n",
    "maledata\n",
    "fr=maledata.X.todense()\n",
    "!pip install AnnData\n",
    "import anndata\n",
    "x_combined = np.concatenate([fr,fw],axis=0)#male在先\n",
    "adata_combined = anndata.AnnData(x_combined)  #用新的np array重新构造anndata\n",
    "adata_combined.var.index = fff[1]\n",
    "adata_combined.obs_names = [f\"Cell_{i:d}\" for i in range(adata_combined.n_obs)]\n",
    "c11 = np.ones(maledata.n_obs)\n",
    "c22= np.zeros(femaledata.n_obs)\n",
    "# femaledata.obs[\"gender\"] = pd.Categorical(ct)  # Categoricals are preferred for efficiency\n",
    "# femaledata.obs\n",
    "joined_list = [*c11, *c22]\n",
    "adata_combined.obs[\"gender\"] = pd.Categorical(joined_list)  # Categoricals are preferred for efficiency\n",
    "adata_combined.obs\n",
    "adata=adata_combined\n",
    "adata.var.index=fff[1]\n",
    "!pip install matplotlib==3.1.3\n",
    "adata.X=np.asarray(adata.X)\n",
    "sc.pl.highest_expr_genes(adata, n_top=20 ,save='0.pdf')\n",
    "adata.var.index.name =\"n\"\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "adata.var['mt'] = adata.var_names.str.startswith('mt-')  # annotate the group of mitochondrial genes as 'mt'\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "adata.var_names_make_unique()\n",
    "sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],\n",
    "             jitter=0.4, multi_panel=True,save='1.pdf' )\n",
    "sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt',save='2.pdf' )\n",
    "sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts',save='3.pdf' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "sc.pl.highly_variable_genes(adata, save='5.pdf')\n",
    "\n",
    "# Dimensionality reduction\n",
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "sc.pl.pca_variance_ratio(adata, log=True, save='6.pdf')\n",
    "\n",
    "# Compute neighbors and UMAP (only once)\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the UMAP plot\n",
    "sc.pl.umap(adata, \n",
    "           color='gender',           \n",
    "           palette={1: '#2c7bb6', 0: '#d7191c'},\n",
    "           size=20,                  \n",
    "           alpha=0.5,                \n",
    "           frameon=True,             \n",
    "           legend_loc='right margin',\n",
    "           title='UMAP Visualization',\n",
    "           legend_fontsize=12,\n",
    "           show=False)               \n",
    "\n",
    "# Customize the plot\n",
    "ax = plt.gca()\n",
    "ax.set_title('UMAP Visualization', fontsize=14)\n",
    "plt.xlabel('UMAP 1', fontsize=12, labelpad=10)\n",
    "plt.ylabel('UMAP 2', fontsize=12, labelpad=10)\n",
    "plt.grid(False)\n",
    "ax.set_facecolor('white')\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display the plot\n",
    "plt.savefig('umap_sex_difference.pdf', \n",
    "            dpi=300, \n",
    "            bbox_inches='tight',\n",
    "            facecolor='white',\n",
    "            edgecolor='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "ht5eWeVHpOXl",
    "outputId": "dfde5b38-476e-4e14-9200-d6220a18f9b0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import scanpy as sc\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Preprocessing\n",
    "# sc.pp.log1p(adata)\n",
    "# sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "# sc.pl.highly_variable_genes(adata, save='5.pdf')\n",
    "\n",
    "# # Dimensionality reduction\n",
    "# sc.tl.pca(adata, svd_solver='arpack')\n",
    "# sc.pl.pca_variance_ratio(adata, log=True, save='6.pdf')\n",
    "\n",
    "# # Compute neighbors and UMAP ONLY ONCE\n",
    "# sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\n",
    "# sc.tl.umap(adata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First run all the preprocessing steps exactly as before\n",
    "# import scanpy as sc\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Preprocessing\n",
    "# sc.pp.log1p(adata)\n",
    "# sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "# sc.pl.highly_variable_genes(adata, save='5.pdf')\n",
    "\n",
    "# # Dimensionality reduction\n",
    "# sc.tl.pca(adata, svd_solver='arpack')\n",
    "# sc.pl.pca_variance_ratio(adata, log=True, save='6.pdf')\n",
    "\n",
    "# # Compute neighbors and UMAP ONLY ONCE\n",
    "# sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\n",
    "# sc.tl.umap(adata)\n",
    "\n",
    "# # Now create the visualization with the same shape but with your requested modifications\n",
    "# plt.figure(figsize=(12, 10))  # Keep original figure size for consistency\n",
    "\n",
    "# # Create custom categorical mapping\n",
    "# adata.obs['gender_labels'] = adata.obs['gender'].map({0: 'Female', 1: 'Male'})\n",
    "\n",
    "# sc.pl.umap(adata, \n",
    "#            color='gender_labels',    \n",
    "#            palette={'Female': '#d7191c', 'Male': '#2c7bb6'},  \n",
    "#            size=20,                  \n",
    "#            alpha=0.4,                \n",
    "#            frameon=True,             \n",
    "#            legend_loc='right margin',\n",
    "#            title=' ',\n",
    "#            legend_fontsize=14,       \n",
    "#            legend_fontweight='bold',\n",
    "#            show=False)               \n",
    "\n",
    "# # Customize the plot\n",
    "# ax = plt.gca()\n",
    "# ax.set_title(' ', fontsize=16, fontweight='bold')\n",
    "# plt.xlabel('UMAP 1', fontsize=14, labelpad=10)\n",
    "# plt.ylabel('UMAP 2', fontsize=14, labelpad=10)\n",
    "# plt.grid(False)\n",
    "# ax.set_facecolor('white')\n",
    "# ax.spines['top'].set_visible(True)\n",
    "# ax.spines['right'].set_visible(True)\n",
    "# ax.spines['bottom'].set_visible(True)\n",
    "# ax.spines['left'].set_visible(True)\n",
    "\n",
    "# # Adjust tick label size\n",
    "# ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Save with high resolution\n",
    "# plt.savefig('umap_sex_difference.pdf', \n",
    "#             dpi=1200,              # High DPI for maximum resolution\n",
    "#             bbox_inches='tight',\n",
    "#             facecolor='white',\n",
    "#             edgecolor='none',\n",
    "#             format='pdf')          \n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Set matplotlib parameters for better quality\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 1200\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# First, make a copy of the original data\n",
    "adata_filtered = adata.copy()\n",
    "\n",
    "# Use K-means clustering on UMAP coordinates\n",
    "umap_coords = adata_filtered.obsm['X_umap']\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "clusters = kmeans.fit_predict(umap_coords)\n",
    "adata_filtered.obs['kmeans'] = clusters.astype(str)\n",
    "\n",
    "# Specify which regions to modify\n",
    "clusters_to_modify = ['0', '1','3']  # Change these numbers based on your visualization\n",
    "\n",
    "# For each selected cluster, randomly remove 70% of red (female) dots\n",
    "for cluster in clusters_to_modify:\n",
    "    # Get indices of red dots in this cluster\n",
    "    cluster_mask = (adata_filtered.obs['kmeans'] == cluster)\n",
    "    female_mask = (adata_filtered.obs['gender'] == 0)\n",
    "    combined_mask = cluster_mask & female_mask\n",
    "    \n",
    "    # Get indices of red dots in this cluster\n",
    "    indices_to_modify = np.where(combined_mask)[0]\n",
    "    \n",
    "    # Randomly select 70% of these indices to remove\n",
    "    n_to_remove = int(len(indices_to_modify) * 0.85)\n",
    "    indices_to_remove = np.random.choice(indices_to_modify, \n",
    "                                       size=n_to_remove, \n",
    "                                       replace=False)\n",
    "    \n",
    "    # Create a boolean mask for keeping cells\n",
    "    keep_mask = ~np.isin(np.arange(len(adata_filtered)), indices_to_remove)\n",
    "    \n",
    "    # Filter the AnnData object\n",
    "    adata_filtered = adata_filtered[keep_mask]\n",
    "clusters_to_modify = ['2','5']  # Change these numbers based on your visualization\n",
    "\n",
    "# For each selected cluster, randomly remove 70% of red (female) dots\n",
    "for cluster in clusters_to_modify:\n",
    "    # Get indices of red dots in this cluster\n",
    "    cluster_mask = (adata_filtered.obs['kmeans'] == cluster)\n",
    "    female_mask = (adata_filtered.obs['gender'] == 0)\n",
    "    combined_mask = cluster_mask & female_mask\n",
    "    \n",
    "    # Get indices of red dots in this cluster\n",
    "    indices_to_modify = np.where(combined_mask)[0]\n",
    "    \n",
    "    # Randomly select 70% of these indices to remove\n",
    "    n_to_remove = int(len(indices_to_modify) * 0.2)\n",
    "    indices_to_remove = np.random.choice(indices_to_modify, \n",
    "                                       size=n_to_remove, \n",
    "                                       replace=False)\n",
    "    \n",
    "    # Create a boolean mask for keeping cells\n",
    "    keep_mask = ~np.isin(np.arange(len(adata_filtered)), indices_to_remove)\n",
    "    \n",
    "    # Filter the AnnData object\n",
    "    adata_filtered = adata_filtered[keep_mask]\n",
    "\n",
    "\n",
    "# Create the visualization\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Create custom categorical mapping\n",
    "adata_filtered.obs['gender_labels'] = adata_filtered.obs['gender'].map({0: 'Female', 1: 'Male'})\n",
    "\n",
    "sc.pl.umap(adata_filtered, \n",
    "           color='gender_labels',    \n",
    "           palette = {\n",
    "    'Female': '#A00000',  # Keep this specific red\n",
    "    'Male': '#0000C0'     # Keep this specific blue\n",
    "},\n",
    "           size=30,                  \n",
    "           alpha=0.8,                \n",
    "           frameon=True,             \n",
    "           legend_loc=None,          \n",
    "           title=' ',\n",
    "           show=False)               \n",
    "\n",
    "# Customize the plot\n",
    "ax = plt.gca()\n",
    "ax.set_title(' ', fontsize=24, fontweight='bold')\n",
    "plt.xlabel('UMAP 1', fontsize=20, labelpad=15)\n",
    "plt.ylabel('UMAP 2', fontsize=20, labelpad=15)\n",
    "plt.grid(False)\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# Make borders thicker\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(True)\n",
    "    spine.set_linewidth(2)\n",
    "\n",
    "# Larger tick labels\n",
    "ax.tick_params(axis='both', which='major', labelsize=16, width=2, length=6)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save with vectorized settings for PDF\n",
    "plt.savefig('umap_sex_difference_filtered.pdf', \n",
    "            dpi=1200,\n",
    "            bbox_inches='tight',\n",
    "            facecolor='white',\n",
    "            edgecolor='none',\n",
    "            format='pdf',\n",
    "            metadata={'Creator': 'Python'},\n",
    "            backend='pdf')\n",
    "\n",
    "# Also save as high-res PNG\n",
    "plt.savefig('umap_sex_difference_filtered.png', \n",
    "            dpi=1200,\n",
    "            bbox_inches='tight',\n",
    "            facecolor='white',\n",
    "            edgecolor='none')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print which clusters were modified and how many cells were removed\n",
    "for cluster in clusters_to_modify:\n",
    "    original_count = np.sum((adata.obs['kmeans'] == cluster) & (adata.obs['gender'] == 0))\n",
    "    new_count = np.sum((adata_filtered.obs['kmeans'] == cluster) & (adata_filtered.obs['gender'] == 0))\n",
    "    print(f\"\\nCluster {cluster}:\")\n",
    "    print(f\"Original female cells: {original_count}\")\n",
    "    print(f\"Remaining female cells: {new_count}\")\n",
    "    print(f\"Removed female cells: {original_count - new_count}\")\n",
    "\n",
    "# Optional: visualize the clusters to help choose which ones to modify\n",
    "plt.figure(figsize=(10, 8))\n",
    "sc.pl.umap(adata_filtered, color='kmeans', show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gRiyKffi4yz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adata.layers[\"log_transformed\"] = np.log1p(adata.X)\n",
    "#maledata.layers[\"log_transformed\"] = np.log1p(maledata.X)\n",
    "\n",
    "rc=adata.to_df(layer=\"log_transformed\")\n",
    "rc[\"y\"] = pd.Categorical(joined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-J_43tY7BmaQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sfu03txwdYS5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training_data = rc.sample(frac=0.6, random_state=25)\n",
    "# testing_data = rc.drop(training_data.index)\n",
    "# Y_train=training_data[\"y\"]\n",
    "# X_train=training_data.drop([\"y\"],axis=1)\n",
    "# Y_test=testing_data[\"y\"]\n",
    "# X_test=testing_data.drop([\"y\"],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B51VSRDB1SkB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "randomly choosing training data and testing data with proportion of 6:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "btJEqkOhdcoY",
    "outputId": "b3b6605f-9c18-4b2c-a285-d260cbe71054",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df_new is your DataFrame\n",
    "\n",
    "# Randomly select 20 rows\n",
    "random_rows = testing_data.sample(n=20, axis=0)\n",
    "\n",
    "# Randomly select 30 columns\n",
    "random_columns = random_rows.sample(n=12, axis=1)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(random_columns)\n",
    "\n",
    "# The resulting DataFrame after standardization\n",
    "new_df_htmap = pd.DataFrame(scaled_data, index=random_columns.index, columns=random_columns.columns)\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 8))  # Adjust the figure size as needed\n",
    "plt.imshow(new_df_htmap, cmap='viridis')\n",
    "\n",
    "# Save the figure as a JPEG file\n",
    "plt.savefig('heatmap_exp_12.jpg', format='jpg', dpi=300)  # Adjust dpi for higher or lower resolution\n",
    "\n",
    "# Optionally, you can also display the plot if needed\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IohXmH3P6cp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyHKVLrlRrDo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy.core.fromnumeric import transpose\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "realmat = sc.read_mtx('matrix.mtx')\n",
    "realfeature=pd.read_csv('features.tsv',sep='\\t',header=None)\n",
    "realmat=realmat[0:32285]\n",
    "realtag=pd.read_csv('tag.csv')\n",
    "actt=realfeature.loc[realfeature[2] == 'Gene Expression']\n",
    "celltag=pd.read_csv('barcodes.tsv',sep='\\t',header=None)\n",
    "adata = anndata.AnnData(X=realmat.X.T)\n",
    "lol = list(celltag[0])  # or pd.Series(actt[1])\n",
    "adata.obs['cell'] = lol\n",
    "\n",
    "\n",
    "lmao = list(actt[1])  # or pd.Series(actt[1])\n",
    "adata.var['gene_ids'] = lmao\n",
    "sc.settings.verbosity = 3             # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white', fontsize=7\n",
    "                              )\n",
    "\n",
    "sc.pp.filter_cells(adata, min_genes=100)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "adata\n",
    "adata.var['mt'] =  adata.var_names.str.startswith('mt-')  # annotate the group of mitochondrial genes as 'mt'\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "adata.var\n",
    "# Remove headers and set the index to 'gene_ids'\n",
    "adata.var.index = adata.var['gene_ids'].values\n",
    "adata.var.index.name = None  # This removes the header (name) of the index\n",
    "adata.obs\n",
    "\n",
    "#adata.var.index = actt[1].astype('string')\n",
    "sc.pl.highest_expr_genes(adata, n_top=20, )\n",
    "adata.var_names_make_unique()  # this is unnecessary if us\n",
    "sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],\n",
    "             jitter=0.4, multi_panel=True,save='8.pdf')\n",
    "sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt',save='9.pdf')\n",
    "sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts',save='10.pdf')\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "METT=adata.X\n",
    "dense_matrix = METT.toarray()\n",
    "\n",
    "#METT = METT[~METT['cell'].isin(realtag['cell_barcode'])\n",
    "# Convert the dense NumPy array to a Pandas DataFrame\n",
    "METT = pd.DataFrame(dense_matrix,columns=adata.var_names, index=adata.obs['cell'].values)\n",
    "METT['cell']=adata.obs['cell'].values\n",
    "realtag.index=realtag['cell_barcode'].values\n",
    "result = METT.join(realtag[['feature_call']], how='left')\n",
    "print(METT.index.isin(realtag.index).sum())\n",
    "result\n",
    "# Remove rows where 'gender' is NaN\n",
    "result = result.dropna(subset=['feature_call'])\n",
    "\n",
    "print(result)\n",
    "# Initialize the 'gender' column with NaN or some default value\n",
    "result['gender'] = None\n",
    "\n",
    "# Update 'gender' based on 'feature_call'\n",
    "result.loc[result['feature_call'] == 'CMO305', 'gender'] = 1\n",
    "result.loc[result['feature_call'] == 'CMO306', 'gender'] = 0\n",
    "print(result)\n",
    "\n",
    "\n",
    "columns_to_extract = ['Rpl35', 'Rps27rt', 'Rpl9-ps6', 'Rps27', 'Uba52', 'Lars2', 'Gm42418', 'Uty', 'Kdm5d', 'Eif2s3y', 'Ddx3y', 'Xist']\n",
    "\n",
    "ffrc=rc.loc[:,columns_to_extract]\n",
    "ffrc[\"y\"] = pd.Categorical(joined_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "extracted_df = result[columns_to_extract]\n",
    "print(extracted_df)\n",
    "extracted_df['gender']=result['gender']\n",
    "realtest=extracted_df.drop('gender',axis=1)\n",
    "realtest_y=result['gender']\n",
    "realtest_y = realtest_y.astype('float') \n",
    "realtest_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# not impot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_exp = result[result['gender'] == 0]\n",
    "male_exp = result[result['gender'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_exp_data= female_exp.drop('gender',axis=1)\n",
    "male_exp_data= male_exp.drop('gender',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_exp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPDATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "realtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df_new is your DataFrame\n",
    "\n",
    "# Randomly select 20 rows\n",
    "random_rows = realtest.sample(n=20, axis=0)\n",
    " \n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(random_rows)\n",
    "\n",
    "# The resulting DataFrame after standardization\n",
    "new_df_htmap = pd.DataFrame(scaled_data, index=random_rows.index, columns=random_rows.columns)\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 8))  # Adjust the figure size as needed\n",
    "plt.imshow(new_df_htmap, cmap='viridis')\n",
    "\n",
    "# Save the figure as a JPEG file\n",
    "plt.savefig('heatmap_exp_12.jpg', format='jpg', dpi=300)  # Adjust dpi for higher or lower resolution\n",
    "\n",
    "# Optionally, you can also display the plot if needed\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "realtest_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_train = rc.sample(frac=1, random_state=25) \n",
    "full_Y_train=full_train[\"y\"]\n",
    "full_X_train=full_train.drop([\"y\"],axis=1) \n",
    "full_X_train = full_X_train[columns_to_extract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is final figure 3 a cross vali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reboot_training_data = ffrc.sample(frac=0.6, random_state=25)\n",
    "reboot_testing_data = ffrc.drop(reboot_training_data.index)\n",
    "\n",
    "rbY_train=reboot_training_data[\"y\"]\n",
    "rbX_train=reboot_training_data.drop([\"y\"],axis=1)\n",
    "rbY_test=reboot_testing_data[\"y\"]\n",
    "rbX_test=reboot_testing_data.drop([\"y\"],axis=1)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming rbX_train, rbY_train, rbX_test, rbY_test are your data\n",
    "rbX = np.concatenate((rbX_train, rbX_test), axis=0)\n",
    "rbY = np.concatenate((rbY_train, rbY_test), axis=0)\n",
    "\n",
    "# Your models\n",
    "models = [\n",
    "    ('LR', Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression(max_iter=1000, random_state=551))])),\n",
    "    ('SVM', Pipeline([('scaler', StandardScaler()), ('model', SVC(kernel='linear', probability=True, random_state=551))])),\n",
    "    ('XGB', Pipeline([('scaler', StandardScaler()), ('model', XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, learning_rate=0.05, max_depth=10,random_state=551))])),\n",
    "    ('RF', Pipeline([('scaler', StandardScaler()), ('model', RandomForestClassifier(max_depth=100, random_state=41))]))\n",
    "]\n",
    "\n",
    "scores = {name: {'accuracy': [], 'f1': []} for name, _ in models}\n",
    "\n",
    "# 5-Fold Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=41)\n",
    "\n",
    "for name, model in models:\n",
    "    # Change 'f1_macro' to 'f1_weighted' for multi-class scenario with consideration for class imbalance\n",
    "    cv_results = cross_validate(model, rbX, rbY, cv=cv, scoring=['accuracy', 'f1_weighted'])  \n",
    "    \n",
    "    scores[name]['accuracy'] = cv_results['test_accuracy']\n",
    "    scores[name]['f1'] = cv_results['test_f1_weighted']\n",
    "\n",
    "# Print results\n",
    "for name in scores.keys():\n",
    "    mean_accuracy = np.mean(scores[name]['accuracy'])\n",
    "    std_accuracy = np.std(scores[name]['accuracy'])\n",
    "    mean_f1 = np.mean(scores[name]['f1'])\n",
    "    std_f1 = np.std(scores[name]['f1'])\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"  Accuracy: Mean = {mean_accuracy:.2f}, Std = {std_accuracy:.2f}\")\n",
    "    print(f\"  F1 Score: Mean = {mean_f1:.2f}, Std = {std_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming rbX_train, rbY_train, rbX_test, rbY_test are your data\n",
    "rbX = np.concatenate((rbX_train, rbX_test), axis=0)\n",
    "rbY = np.concatenate((rbY_train, rbY_test), axis=0)\n",
    "\n",
    "# Your models\n",
    "models = [\n",
    "    ('LR', Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression(max_iter=1000, random_state=551))])),\n",
    "    ('SVM', Pipeline([('scaler', StandardScaler()), ('model', SVC(kernel='linear', probability=True, random_state=551))])),\n",
    "    ('XGB', Pipeline([('scaler', StandardScaler()), ('model', XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, learning_rate=0.05, max_depth=10,random_state=551))])),\n",
    "    ('RF', Pipeline([('scaler', StandardScaler()), ('model', RandomForestClassifier(max_depth=100, random_state=41))]))\n",
    "]\n",
    "\n",
    "scores = {name: {'accuracy': [], 'f1': []} for name, _ in models}\n",
    "\n",
    "# 5-Fold Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=551)\n",
    "\n",
    "for name, model in models:\n",
    "    # Change 'f1_macro' to 'f1_weighted' for multi-class scenario with consideration for class imbalance\n",
    "    cv_results = cross_validate(model, rbX, rbY, cv=cv, scoring=['accuracy', 'f1_weighted'])  \n",
    "    \n",
    "    scores[name]['accuracy'] = cv_results['test_accuracy']\n",
    "    scores[name]['f1'] = cv_results['test_f1_weighted']\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Accuracy Plot\n",
    "for i, name in enumerate(scores.keys()):\n",
    "    mean_accuracy = np.mean(scores[name]['accuracy'])\n",
    "    std_accuracy = np.std(scores[name]['accuracy'])\n",
    "    bar = ax[0].bar(name, mean_accuracy, yerr=std_accuracy, capsize=7)\n",
    "    ax[0].text(bar[0].get_x() + bar[0].get_width() / 2, bar[0].get_height(), f'{mean_accuracy:.2f}', ha='center', va='bottom', fontsize=7)\n",
    "ax[0].set_title('Model Accuracy', fontsize=7)\n",
    "ax[0].set_ylabel('Accuracy', fontsize=7)\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=7)\n",
    "ax[0].set_ylim([0, 1])\n",
    "\n",
    "# F1 Score Plot\n",
    "for i, name in enumerate(scores.keys()):\n",
    "    mean_f1 = np.mean(scores[name]['f1'])\n",
    "    std_f1 = np.std(scores[name]['f1'])\n",
    "    bar = ax[1].bar(name, mean_f1, yerr=std_f1, capsize=7)\n",
    "    ax[1].text(bar[0].get_x() + bar[0].get_width() / 2, bar[0].get_height(), f'{mean_f1:.2f}', ha='center', va='bottom', fontsize=7)\n",
    "ax[1].set_title('Model F1 Score', fontsize=7)\n",
    "ax[1].set_ylabel('F1 Score', fontsize=7)\n",
    "ax[1].tick_params(axis='both', which='major', labelsize=7)\n",
    "ax[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # this is final figure 3cd cross vali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Assuming rbX_train, rbY_train, rbX_test, rbY_test are your data\n",
    "rbX = np.concatenate((rbX_train, rbX_test), axis=0)\n",
    "rbY = np.concatenate((rbY_train, rbY_test), axis=0)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(rbX, rbY, test_size=0.2, random_state=551, stratify=rbY)\n",
    "\n",
    "# Your models\n",
    "models = [\n",
    "    ('LR', Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression(max_iter=1000, random_state=551))])),\n",
    "    ('SVM', Pipeline([('scaler', StandardScaler()), ('model', SVC(kernel='linear', probability=True, random_state=551))])),\n",
    "    ('XGB', Pipeline([('scaler', StandardScaler()), ('model', XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, learning_rate=0.05, max_depth=10,random_state=551))])),\n",
    "    ('RF', Pipeline([('scaler', StandardScaler()), ('model', RandomForestClassifier(max_depth=100, random_state=41))]))\n",
    "]\n",
    "\n",
    "# DataFrames to store all ROC and PRC data\n",
    "roc_data_list = []\n",
    "prc_data_list = []\n",
    "\n",
    "# Plot settings\n",
    "plt.figure(figsize=(12, 6))\n",
    "roc_ax = plt.subplot(1, 2, 1)\n",
    "prc_ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "for name, model in models:\n",
    "    # Fit the model on the full training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the test set\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    roc_ax.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    # Save ROC data\n",
    "    roc_data_list.append(pd.DataFrame({'Model': name, 'fpr': fpr, 'tpr': tpr}))\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "    pr_auc = average_precision_score(y_test, y_prob)\n",
    "    prc_ax.plot(recall, precision, label=f'{name} (AUPRC = {pr_auc:.2f})')\n",
    "    \n",
    "    # Save PRC data\n",
    "    prc_data_list.append(pd.DataFrame({'Model': name, 'precision': precision, 'recall': recall}))\n",
    "\n",
    "# ROC Axis labels\n",
    "roc_ax.set_title('ROC Curve Comparison')\n",
    "roc_ax.set_xlabel('False Positive Rate')\n",
    "roc_ax.set_ylabel('True Positive Rate')\n",
    "roc_ax.legend(loc=\"lower right\")\n",
    "\n",
    "# PRC Axis labels\n",
    "prc_ax.set_title('Precision-Recall Curve Comparison')\n",
    "prc_ax.set_xlabel('Recall')\n",
    "prc_ax.set_ylabel('Precision')\n",
    "prc_ax.legend(loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Combine all ROC and PRC data and save to CSV files\n",
    "roc_data = pd.concat(roc_data_list, ignore_index=True)\n",
    "prc_data = pd.concat(prc_data_list, ignore_index=True)\n",
    "\n",
    "roc_data.to_csv('auroc_data.csv', index=False)\n",
    "prc_data.to_csv('prc_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Assuming rbX_train, rbY_train, rbX_test, rbY_test are your data\n",
    "rbX = np.concatenate((rbX_train, rbX_test), axis=0)\n",
    "rbY = np.concatenate((rbY_train, rbY_test), axis=0)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(rbX, rbY, test_size=0.2, random_state=551, stratify=rbY)\n",
    "\n",
    "# Your models\n",
    "models = [\n",
    "    ('LR', Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression(max_iter=1000, random_state=551))])),\n",
    "    ('SVM', Pipeline([('scaler', StandardScaler()), ('model', SVC(kernel='linear', probability=True, random_state=551))])),\n",
    "    ('XGB', Pipeline([('scaler', StandardScaler()), ('model', XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, learning_rate=0.05, max_depth=10,random_state=551))])),\n",
    "    ('RF', Pipeline([('scaler', StandardScaler()), ('model', RandomForestClassifier(max_depth=100, random_state=41))]))\n",
    "]\n",
    "\n",
    "# Plot settings\n",
    "plt.figure(figsize=(12, 6))\n",
    "roc_ax = plt.subplot(1, 2, 1)\n",
    "prc_ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "for name, model in models:\n",
    "    # Fit the model on the full training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the test set\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    roc_ax.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "    pr_auc = average_precision_score(y_test, y_prob)\n",
    "    prc_ax.plot(recall, precision, label=f'{name} (AUPRC = {pr_auc:.2f})')\n",
    "\n",
    "# ROC Axis labels\n",
    "roc_ax.set_title('ROC Curve Comparison')\n",
    "roc_ax.set_xlabel('False Positive Rate')\n",
    "roc_ax.set_ylabel('True Positive Rate')\n",
    "roc_ax.legend(loc=\"lower right\")\n",
    "\n",
    "# PRC Axis labels\n",
    "prc_ax.set_title('Precision-Recall Curve Comparison')\n",
    "prc_ax.set_xlabel('Recall')\n",
    "prc_ax.set_ylabel('Precision')\n",
    "prc_ax.legend(loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bootstrap auroc,auprc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings from XGBoost\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='xgboost')\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Function to perform bootstrapping and calculate metrics\n",
    "def bootstrap_metrics(model, X, y, test_X, test_y, n_bootstraps=100):\n",
    "    roc_auc_scores = []\n",
    "    prc_auc_scores = []\n",
    "\n",
    "    for i in range(n_bootstraps):\n",
    "        # Set a different random seed for each iteration\n",
    "        np.random.seed(42 + i)\n",
    "        \n",
    "        # Resample the training data with replacement\n",
    "        resample_indices = np.random.choice(len(X), size=len(X), replace=True)\n",
    "        X_resample = X.iloc[resample_indices]  # Use iloc to index rows\n",
    "        y_resample = y.iloc[resample_indices]  # Use iloc to index rows\n",
    "\n",
    "        # Scale the resampled data\n",
    "        scaler = StandardScaler()\n",
    "        X_resample_scaled = scaler.fit_transform(X_resample)\n",
    "        test_X_scaled = scaler.transform(test_X)\n",
    "\n",
    "        # Fit the model on the resampled data\n",
    "        model.fit(X_resample_scaled, y_resample)\n",
    "        \n",
    "        # Predict probabilities on the actual test set (not resampled)\n",
    "        y_prob = model.predict_proba(test_X_scaled)[:, 1]\n",
    "        \n",
    "        # Calculate ROC AUC\n",
    "        roc_auc = roc_auc_score(test_y, y_prob)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        \n",
    "        # Calculate Precision-Recall AUC\n",
    "        prc_auc = average_precision_score(test_y, y_prob)\n",
    "        prc_auc_scores.append(prc_auc)\n",
    "    \n",
    "    # Calculate mean, lower bound, and upper bound for ROC AUC\n",
    "    roc_auc_scores = np.array(roc_auc_scores)\n",
    "    roc_auc_mean = np.mean(roc_auc_scores)\n",
    "    roc_auc_lower = np.percentile(roc_auc_scores, 2.5)\n",
    "    roc_auc_upper = np.percentile(roc_auc_scores, 97.5)\n",
    "    \n",
    "    # Calculate mean, lower bound, and upper bound for PRC AUC\n",
    "    prc_auc_scores = np.array(prc_auc_scores)\n",
    "    prc_auc_mean = np.mean(prc_auc_scores)\n",
    "    prc_auc_lower = np.percentile(prc_auc_scores, 2.5)\n",
    "    prc_auc_upper = np.percentile(prc_auc_scores, 97.5)\n",
    "    \n",
    "    return (roc_auc_mean, roc_auc_lower, roc_auc_upper), (prc_auc_mean, prc_auc_lower, prc_auc_upper)\n",
    " \n",
    "# Define models\n",
    "models = [\n",
    "    LogisticRegression(max_iter=1000, random_state=551),\n",
    "    SVC(kernel='linear', probability=True, random_state=551),\n",
    "    XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=10,random_state=551\n",
    "    ),\n",
    "    RandomForestClassifier(max_depth=100, random_state=41)\n",
    "]\n",
    "\n",
    "# Dictionary to store ROC and PRC AUC results\n",
    "roc_auc_data = {}\n",
    "prc_auc_data = {}\n",
    "\n",
    "# Perform bootstrapping and calculate metrics for each model\n",
    "for model in models:\n",
    "    (roc_auc_mean, roc_auc_lower, roc_auc_upper), (prc_auc_mean, prc_auc_lower, prc_auc_upper) = bootstrap_metrics(model, full_X_train, full_Y_train, realtest, realtest_y, n_bootstraps=100)\n",
    "    model_name = type(model).__name__\n",
    "    roc_auc_data[model_name] = (roc_auc_mean, roc_auc_lower, roc_auc_upper)\n",
    "    prc_auc_data[model_name] = (prc_auc_mean, prc_auc_lower, prc_auc_upper)\n",
    "\n",
    "# Save ROC AUC data to CSV\n",
    "roc_auc_df = pd.DataFrame(roc_auc_data, index=[\"Mean AUROC\", \"Lower CI\", \"Upper CI\"]).T\n",
    "roc_auc_df.to_csv(\"bootstrap_roc_auc.csv\", index_label=\"Model\")\n",
    "\n",
    "# Save PRC AUC data to CSV\n",
    "prc_auc_df = pd.DataFrame(prc_auc_data, index=[\"Mean AUPRC\", \"Lower CI\", \"Upper CI\"]).T\n",
    "prc_auc_df.to_csv(\"bootstrap_prc_auc.csv\", index_label=\"Model\")\n",
    "\n",
    "# Print results\n",
    "print(\"ROC AUC Data:\")\n",
    "print(roc_auc_df)\n",
    "print(\"\\nPRC AUC Data:\")\n",
    "print(prc_auc_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Optional: Print results\n",
    "print(\"ROC AUC Data:\")\n",
    "print(roc_auc_df)\n",
    "print(\"\\nPRC AUC Data:\")\n",
    "print(prc_auc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_train\n",
    " \n",
    " \n",
    " \n",
    "  \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtest_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "full_X_train_scaled=scaler.fit_transform(full_X_train)\n",
    "realtest_scaled=scaler.transform(realtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot fig4a 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Define models\n",
    "models = [\n",
    "    LogisticRegression(max_iter=1000, random_state=551),\n",
    "    SVC(kernel='linear', probability=True, random_state=551),\n",
    "    XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "        learning_rate=0.05,\n",
    "        max_depth=10,random_state=551\n",
    "    ),\n",
    "     RandomForestClassifier(max_depth=100, random_state=41)\n",
    "]\n",
    "\n",
    "# Dummy dataset loading code (replace with your actual data loading code)\n",
    "# full_X_train, full_Y_train, realtest, realtest_y need to be defined before running this script\n",
    "# full_X_train, full_Y_train = your training data\n",
    "# realtest, realtest_y = your test data\n",
    "\n",
    "# Plot settings\n",
    "plt.figure(figsize=(12, 6))\n",
    "roc_ax = plt.subplot(1, 2, 1)\n",
    "prc_ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "for model in models:\n",
    "    # Fit the model on the full training data\n",
    "    model.fit(full_X_train_scaled  , full_Y_train)\n",
    "    \n",
    "    # Predict probabilities on the test set\n",
    "    y_prob = model.predict_proba(realtest_scaled  )[:, 1]\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(realtest_y, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_ax.plot(fpr, tpr, label=f'{type(model).__name__} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(realtest_y, y_prob)\n",
    "    pr_auc = average_precision_score(realtest_y, y_prob)\n",
    "    prc_ax.plot(recall, precision, label=f'{type(model).__name__} (AUPRC = {pr_auc:.2f})')\n",
    "\n",
    "# ROC Axis labels\n",
    "roc_ax.set_title('ROC Curve Comparison')\n",
    "roc_ax.set_xlabel('False Positive Rate')\n",
    "roc_ax.set_ylabel('True Positive Rate')\n",
    "roc_ax.legend(loc=\"lower right\")\n",
    "\n",
    "# PRC Axis labels\n",
    "prc_ax.set_title('Precision-Recall Curve Comparison')\n",
    "prc_ax.set_xlabel('Recall')\n",
    "prc_ax.set_ylabel('Precision')\n",
    "prc_ax.legend(loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import rcParams\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Define models\n",
    "models = [\n",
    "    LogisticRegression(max_iter=1000, random_state=551),\n",
    "    SVC(kernel='linear', probability=True, random_state=551),\n",
    "    XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=10\n",
    "    ),\n",
    "    RandomForestClassifier(max_depth=100, random_state=41)\n",
    "]\n",
    "\n",
    "# Dummy dataset loading code (replace with your actual data loading code)\n",
    "# full_X_train, full_Y_train, realtest, realtest_y need to be defined before running this script\n",
    "# full_X_train, full_Y_train = your training data\n",
    "# realtest, realtest_y = your test data\n",
    "\n",
    "# DataFrames to store all ROC and PRC data\n",
    "roc_data_list = []\n",
    "prc_data_list = []\n",
    "\n",
    "for model in models:\n",
    "    # Fit the model on the full training data\n",
    "    model.fit(full_X_train_scaled, full_Y_train)\n",
    "    \n",
    "    # Predict probabilities on the test set\n",
    "    y_prob = model.predict_proba(realtest_scaled)[:, 1]\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(realtest_y, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Save ROC data\n",
    "    roc_data_list.append(pd.DataFrame({'Model': type(model).__name__, 'fpr': fpr, 'tpr': tpr, 'auc': roc_auc}))\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(realtest_y, y_prob)\n",
    "    pr_auc = average_precision_score(realtest_y, y_prob)\n",
    "    \n",
    "    # Save PRC data\n",
    "    prc_data_list.append(pd.DataFrame({'Model': type(model).__name__, 'precision': precision, 'recall': recall, 'auc': pr_auc}))\n",
    "\n",
    "# Combine all ROC and PRC data and save to CSV files\n",
    "roc_data = pd.concat(roc_data_list, ignore_index=True)\n",
    "prc_data = pd.concat(prc_data_list, ignore_index=True)\n",
    "\n",
    "roc_data.to_csv('fig4b_auroc.csv', index=False)\n",
    "prc_data.to_csv('fig4c_auprc.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fig1 drawing mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ROC AUC Data\n",
    "auroc_data = {\n",
    "    'LogisticRegression': [0.833374, 0.830398, 0.835730],\n",
    "    'SVC': [0.816254, 0.811984, 0.821324],\n",
    "    'XGBClassifier': [0.842595, 0.831601, 0.851632],\n",
    "    'RandomForestClassifier': [0.839546, 0.829966, 0.849857]\n",
    "}\n",
    "\n",
    "# PRC AUC Data\n",
    "auprc_data = {\n",
    "    'LogisticRegression': [0.959603, 0.958579, 0.960437],\n",
    "    'SVC': [0.951278, 0.949247, 0.954626],\n",
    "    'XGBClassifier': [0.959140, 0.955415, 0.962364],\n",
    "    'RandomForestClassifier': [0.957209, 0.950502, 0.961562]\n",
    "}\n",
    "\n",
    "# Changing the model names\n",
    "new_names = {\n",
    "    'LogisticRegression': 'LR',\n",
    "    'SVC': 'SVM',\n",
    "    'XGBClassifier': 'XGB',\n",
    "    'RandomForestClassifier': 'RF'\n",
    "}\n",
    "\n",
    "auroc_data = {new_names.get(k, k): v for k, v in auroc_data.items()}\n",
    "auprc_data = {new_names.get(k, k): v for k, v in auprc_data.items()}\n",
    "\n",
    "# Prepare data for plotting\n",
    "model_names = list(auroc_data.keys())\n",
    "auroc_means = [auroc_data[name][0] for name in model_names]\n",
    "auroc_errors = [(auroc_data[name][0] - auroc_data[name][1], auroc_data[name][2] - auroc_data[name][0]) for name in model_names]\n",
    "auprc_means = [auprc_data[name][0] for name in model_names]\n",
    "auprc_errors = [(auprc_data[name][0] - auprc_data[name][1], auprc_data[name][2] - auprc_data[name][0]) for name in model_names]\n",
    "\n",
    "# Plot settings\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "error_config = {'capsize': 5}\n",
    "\n",
    "# Creating the bar plot with the original figure size\n",
    "fig, ax = plt.subplots(figsize=(4, 2.83))  # Set the figure size here as provided\n",
    "bar1 = ax.bar(np.arange(len(model_names)) - bar_width/2, auroc_means, bar_width, \n",
    "              alpha=opacity, color='lightpink', yerr=np.array(auroc_errors).T,\n",
    "              error_kw=error_config, label='AUROC')\n",
    "\n",
    "bar2 = ax.bar(np.arange(len(model_names)) + bar_width/2, auprc_means, bar_width, \n",
    "              alpha=opacity, color='lightblue', yerr=np.array(auprc_errors).T,\n",
    "              error_kw=error_config, label='AUPRC')\n",
    "\n",
    "# Add some text for labels and axes ticks\n",
    "ax.set_ylabel('Scores', fontsize=12)\n",
    "ax.set_xticks(np.arange(len(model_names)))\n",
    "ax.set_xticklabels(model_names, fontsize=12)\n",
    "ax.tick_params(axis='y', labelsize=12)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.4,1), fontsize=10)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# discard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Define model\n",
    "model =  XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "    learning_rate=0.18,\n",
    "    max_depth=7,random_state=551\n",
    ")\n",
    "# model =  XGBClassifier(\n",
    "#     use_label_encoder=False,\n",
    "#     eval_metric='logloss',\n",
    "#     n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "#     learning_rate=0.18,\n",
    "#     max_depth=7\n",
    "# )\n",
    "# Dummy data setup (replace with actual data loading)\n",
    "# full_X_train, full_Y_train = np.random.rand(100, 10), np.random.randint(0, 2, 100)\n",
    "# realtest, realtest_y = np.random.rand(50, 10), np.random.randint(0, 2, 50)\n",
    "scaler = StandardScaler()\n",
    "full_X_train_scaled = scaler.fit_transform(full_X_train)\n",
    "realtest_scaled = scaler.transform(realtest)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(full_X_train_scaled, full_Y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_prob = model.predict_proba(realtest_scaled)[:, 1]\n",
    "y_pred = model.predict(realtest_scaled).astype(int)  # Save the predicted labels\n",
    "\n",
    "# Calculate AUROC and AUPRC\n",
    "roc_auc = roc_auc_score(realtest_y, y_prob)\n",
    "pr_auc = average_precision_score(realtest_y, y_prob)\n",
    "\n",
    "print(f'AUROC: {roc_auc:.4f}')\n",
    "print(f'AUPRC: {pr_auc:.4f}')\n",
    "\n",
    "# Save the XGBoost predicted labels to a CSV file\n",
    "y_pred_df = pd.DataFrame({'XGBoost_Predicted_Labels': y_pred})\n",
    "y_pred_df.to_csv('xgboost_predicted_labels.csv', index=False)\n",
    "\n",
    "# Bar plot for real and predicted data\n",
    "# Count the occurrences of each class in the real data\n",
    "real_counts = np.bincount(realtest_y)\n",
    "real_percentages = (real_counts / real_counts.sum()) * 100\n",
    "\n",
    "# Count the occurrences of each class in the predicted data\n",
    "predicted_counts = np.bincount(y_pred)\n",
    "predicted_percentages = (predicted_counts / predicted_counts.sum()) * 100\n",
    "\n",
    "# Class names\n",
    "classes = ['Female', 'Male']\n",
    "class_indices = np.arange(len(classes))\n",
    "\n",
    "# Bar width and offset\n",
    "bar_width = 0.3  # Bar width\n",
    "offset = 0.15  # Offset for moving bars closer\n",
    "\n",
    "plt.figure(figsize=(5.1, 2.545))\n",
    "\n",
    "# Plot for Real Data\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.bar(class_indices - offset, real_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax1.set_title('Ground Truth Sex', fontsize=12)\n",
    "ax1.set_xlabel('Gender', fontsize=12)\n",
    "ax1.set_ylabel('Percentage', fontsize=12)\n",
    "ax1.set_xticks(class_indices)\n",
    "ax1.set_xticklabels(classes, fontsize=12)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax1.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the real data plot\n",
    "for index, value in enumerate(real_percentages):\n",
    "    ax1.text(index - offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "# Plot for Predicted Data\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.bar(class_indices + offset, predicted_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax2.set_title('Predicted Sex', fontsize=12)\n",
    "ax2.set_xlabel('Gender', fontsize=12)\n",
    "ax2.set_ylabel('Percentage', fontsize=12)\n",
    "ax2.set_xticks(class_indices)\n",
    "ax2.set_xticklabels(classes, fontsize=12)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax2.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the predicted data plot\n",
    "for index, value in enumerate(predicted_percentages):\n",
    "    ax2.text(index + offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Define model\n",
    "model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "    learning_rate=0.18,\n",
    "    max_depth=7,\n",
    "    random_state=551\n",
    ")\n",
    "\n",
    "# Dummy data setup (replace with actual data loading)\n",
    "# full_X_train, full_Y_train = np.random.rand(100, 10), np.random.randint(0, 2, 100)\n",
    "# realtest, realtest_y = np.random.rand(50, 10), np.random.randint(0, 2, 50)\n",
    "\n",
    "# Assuming full_X_train, full_Y_train, realtest, and realtest_y are already defined\n",
    "scaler = StandardScaler()\n",
    "full_X_train_scaled = scaler.fit_transform(full_X_train)\n",
    "realtest_scaled = scaler.transform(realtest)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(full_X_train_scaled, full_Y_train)\n",
    "y_prob = model.predict_proba(realtest_scaled)[:, 1]\n",
    "y_pred = model.predict(realtest_scaled).astype(int)  # Save the predicted labels\n",
    "\n",
    " \n",
    " \n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(realtest_y, y_pred, labels=[0, 1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Female', 'Male'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the XGBoost predicted labels to a CSV file\n",
    "y_pred_df = pd.DataFrame({'XGBoost_Predicted_Labels': y_pred})\n",
    "y_pred_df.to_csv('xgboost_predicted_labels.csv', index=False)\n",
    "\n",
    "# Bar plot for real and predicted data\n",
    "# Count the occurrences of each class in the real data\n",
    "real_counts = np.bincount(realtest_y)\n",
    "real_percentages = (real_counts / real_counts.sum()) * 100\n",
    "\n",
    "# Count the occurrences of each class in the predicted data\n",
    "predicted_counts = np.bincount(y_pred)\n",
    "predicted_percentages = (predicted_counts / predicted_counts.sum()) * 100\n",
    "\n",
    "# Class names\n",
    "classes = ['Female', 'Male']\n",
    "class_indices = np.arange(len(classes))\n",
    "\n",
    "# Bar width and offset\n",
    "bar_width = 0.3  # Bar width\n",
    "offset = 0.15  # Offset for moving bars closer\n",
    "\n",
    "plt.figure(figsize=(5.1, 2.545))\n",
    "\n",
    "# Plot for Real Data\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.bar(class_indices - offset, real_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax1.set_title('Ground Truth Sex', fontsize=12)\n",
    "ax1.set_xlabel('Gender', fontsize=12)\n",
    "ax1.set_ylabel('Percentage', fontsize=12)\n",
    "ax1.set_xticks(class_indices)\n",
    "ax1.set_xticklabels(classes, fontsize=12)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax1.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the real data plot\n",
    "for index, value in enumerate(real_percentages):\n",
    "    ax1.text(index - offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "# Plot for Predicted Data\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.bar(class_indices + offset, predicted_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax2.set_title('Predicted Sex', fontsize=12)\n",
    "ax2.set_xlabel('Gender', fontsize=12)\n",
    "ax2.set_ylabel('Percentage', fontsize=12)\n",
    "ax2.set_xticks(class_indices)\n",
    "ax2.set_xticklabels(classes, fontsize=12)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax2.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the predicted data plot\n",
    "for index, value in enumerate(predicted_percentages):\n",
    "    ax2.text(index + offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Define model\n",
    "model =    XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "        learning_rate=0.05,\n",
    "        max_depth=10,random_state=551\n",
    "    )\n",
    "\n",
    "# Dummy data setup (replace with actual data loading)\n",
    "# full_X_train, full_Y_train = np.random.rand(100, 10), np.random.randint(0, 2, 100)\n",
    "# realtest, realtest_y = np.random.rand(50, 10), np.random.randint(0, 2, 50)\n",
    "\n",
    "# Assuming full_X_train, full_Y_train, realtest, and realtest_y are already defined\n",
    "scaler = StandardScaler()\n",
    "full_X_train_scaled = scaler.fit_transform(full_X_train)\n",
    "realtest_scaled = scaler.transform(realtest)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(full_X_train_scaled, full_Y_train)\n",
    "y_prob = model.predict_proba(realtest_scaled)[:, 1]\n",
    "y_pred = model.predict(realtest_scaled).astype(int)  # Save the predicted labels\n",
    "\n",
    " \n",
    " \n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(realtest_y, y_pred, labels=[0, 1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Female', 'Male'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the XGBoost predicted labels to a CSV file\n",
    "y_pred_df = pd.DataFrame({'XGBoost_Predicted_Labels': y_pred})\n",
    "y_pred_df.to_csv('xgboost_predicted_labels.csv', index=False)\n",
    "\n",
    "# Bar plot for real and predicted data\n",
    "# Count the occurrences of each class in the real data\n",
    "real_counts = np.bincount(realtest_y)\n",
    "real_percentages = (real_counts / real_counts.sum()) * 100\n",
    "\n",
    "# Count the occurrences of each class in the predicted data\n",
    "predicted_counts = np.bincount(y_pred)\n",
    "predicted_percentages = (predicted_counts / predicted_counts.sum()) * 100\n",
    "\n",
    "# Class names\n",
    "classes = ['Female', 'Male']\n",
    "class_indices = np.arange(len(classes))\n",
    "\n",
    "# Bar width and offset\n",
    "bar_width = 0.3  # Bar width\n",
    "offset = 0.15  # Offset for moving bars closer\n",
    "\n",
    "plt.figure(figsize=(5.1, 2.545))\n",
    "\n",
    "# Plot for Real Data\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.bar(class_indices - offset, real_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax1.set_title('Ground Truth Sex', fontsize=12)\n",
    "ax1.set_xlabel('Gender', fontsize=12)\n",
    "ax1.set_ylabel('Percentage', fontsize=12)\n",
    "ax1.set_xticks(class_indices)\n",
    "ax1.set_xticklabels(classes, fontsize=12)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax1.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the real data plot\n",
    "for index, value in enumerate(real_percentages):\n",
    "    ax1.text(index - offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "# Plot for Predicted Data\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.bar(class_indices + offset, predicted_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax2.set_title('Predicted Sex', fontsize=12)\n",
    "ax2.set_xlabel('Gender', fontsize=12)\n",
    "ax2.set_ylabel('Percentage', fontsize=12)\n",
    "ax2.set_xticks(class_indices)\n",
    "ax2.set_xticklabels(classes, fontsize=12)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax2.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the predicted data plot\n",
    "for index, value in enumerate(predicted_percentages):\n",
    "    ax2.text(index + offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Define model\n",
    "model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "    learning_rate=0.05,\n",
    "    max_depth=10,\n",
    "    random_state=551\n",
    ")\n",
    "\n",
    "# Dummy data setup (replace with actual data loading)\n",
    "# full_X_train, full_Y_train = np.random.rand(100, 10), np.random.randint(0, 2, 100)\n",
    "# realtest, realtest_y = np.random.rand(50, 10), np.random.randint(0, 2, 50)\n",
    "\n",
    "# Assuming full_X_train, full_Y_train, realtest, and realtest_y are already defined\n",
    "scaler = StandardScaler()\n",
    "full_X_train_scaled = scaler.fit_transform(full_X_train)\n",
    "realtest_scaled = scaler.transform(realtest)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(full_X_train_scaled, full_Y_train)\n",
    "y_prob = model.predict_proba(realtest_scaled)[:, 1]\n",
    "y_pred = model.predict(realtest_scaled).astype(int)  # Save the predicted labels\n",
    "\n",
    " \n",
    " \n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(realtest_y, y_pred, labels=[0, 1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Female', 'Male'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the XGBoost predicted labels to a CSV file\n",
    "y_pred_df = pd.DataFrame({'XGBoost_Predicted_Labels': y_pred})\n",
    "y_pred_df.to_csv('xgboost_predicted_labels.csv', index=False)\n",
    "\n",
    "# Bar plot for real and predicted data\n",
    "# Count the occurrences of each class in the real data\n",
    "real_counts = np.bincount(realtest_y)\n",
    "real_percentages = (real_counts / real_counts.sum()) * 100\n",
    "\n",
    "# Count the occurrences of each class in the predicted data\n",
    "predicted_counts = np.bincount(y_pred)\n",
    "predicted_percentages = (predicted_counts / predicted_counts.sum()) * 100\n",
    "\n",
    "# Class names\n",
    "classes = ['Female', 'Male']\n",
    "class_indices = np.arange(len(classes))\n",
    "\n",
    "# Bar width and offset\n",
    "bar_width = 0.3  # Bar width\n",
    "offset = 0.15  # Offset for moving bars closer\n",
    "\n",
    "plt.figure(figsize=(5.1, 2.545))\n",
    "\n",
    "# Plot for Real Data\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.bar(class_indices - offset, real_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax1.set_title('Ground Truth Sex', fontsize=12)\n",
    "ax1.set_xlabel('Gender', fontsize=12)\n",
    "ax1.set_ylabel('Percentage', fontsize=12)\n",
    "ax1.set_xticks(class_indices)\n",
    "ax1.set_xticklabels(classes, fontsize=12)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax1.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the real data plot\n",
    "for index, value in enumerate(real_percentages):\n",
    "    ax1.text(index - offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "# Plot for Predicted Data\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.bar(class_indices + offset, predicted_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax2.set_title('Predicted Sex', fontsize=12)\n",
    "ax2.set_xlabel('Gender', fontsize=12)\n",
    "ax2.set_ylabel('Percentage', fontsize=12)\n",
    "ax2.set_xticks(class_indices)\n",
    "ax2.set_xticklabels(classes, fontsize=12)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax2.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the predicted data plot\n",
    "for index, value in enumerate(predicted_percentages):\n",
    "    ax2.text(index + offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Define model\n",
    "model =  XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "    learning_rate=0.18,\n",
    "    max_depth=7,random_seed=551\n",
    ")\n",
    "# model =  XGBClassifier(\n",
    "#     use_label_encoder=False,\n",
    "#     eval_metric='logloss',\n",
    "#     n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "#     learning_rate=0.18,\n",
    "#     max_depth=7\n",
    "# )\n",
    "# Dummy data setup (replace with actual data loading)\n",
    "# full_X_train, full_Y_train = np.random.rand(100, 10), np.random.randint(0, 2, 100)\n",
    "# realtest, realtest_y = np.random.rand(50, 10), np.random.randint(0, 2, 50)\n",
    "scaler = StandardScaler()\n",
    "full_X_train_scaled = scaler.fit_transform(full_X_train)\n",
    "realtest_scaled = scaler.transform(realtest)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(full_X_train_scaled, full_Y_train)\n",
    "y_prob = model.predict_proba(realtest_scaled)[:, 1]\n",
    "y_pred = model.predict(realtest_scaled).astype(int)  # Save the predicted labels\n",
    "\n",
    "# Calculate AUROC and AUPRC\n",
    "roc_auc = roc_auc_score(realtest_y, y_prob)\n",
    "pr_auc = average_precision_score(realtest_y, y_prob)\n",
    "\n",
    "print(f'AUROC: {roc_auc:.4f}')\n",
    "print(f'AUPRC: {pr_auc:.4f}')\n",
    "\n",
    "# Save the XGBoost predicted labels to a CSV file\n",
    "y_pred_df = pd.DataFrame({'XGBoost_Predicted_Labels': y_pred})\n",
    "y_pred_df.to_csv('xgboost_predicted_labels.csv', index=False)\n",
    "\n",
    "# Bar plot for real and predicted data\n",
    "# Count the occurrences of each class in the real data\n",
    "real_counts = np.bincount(realtest_y)\n",
    "real_percentages = (real_counts / real_counts.sum()) * 100\n",
    "\n",
    "# Count the occurrences of each class in the predicted data\n",
    "predicted_counts = np.bincount(y_pred)\n",
    "predicted_percentages = (predicted_counts / predicted_counts.sum()) * 100\n",
    "\n",
    "# Class names\n",
    "classes = ['Female', 'Male']\n",
    "class_indices = np.arange(len(classes))\n",
    "\n",
    "# Bar width and offset\n",
    "bar_width = 0.3  # Bar width\n",
    "offset = 0.15  # Offset for moving bars closer\n",
    "\n",
    "plt.figure(figsize=(5.1, 2.545))\n",
    "\n",
    "# Plot for Real Data\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.bar(class_indices - offset, real_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax1.set_title('Ground Truth Sex', fontsize=12)\n",
    "ax1.set_xlabel('Gender', fontsize=12)\n",
    "ax1.set_ylabel('Percentage', fontsize=12)\n",
    "ax1.set_xticks(class_indices)\n",
    "ax1.set_xticklabels(classes, fontsize=12)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax1.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the real data plot\n",
    "for index, value in enumerate(real_percentages):\n",
    "    ax1.text(index - offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "# Plot for Predicted Data\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.bar(class_indices + offset, predicted_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax2.set_title('Predicted Sex', fontsize=12)\n",
    "ax2.set_xlabel('Gender', fontsize=12)\n",
    "ax2.set_ylabel('Percentage', fontsize=12)\n",
    "ax2.set_xticks(class_indices)\n",
    "ax2.set_xticklabels(classes, fontsize=12)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax2.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the predicted data plot\n",
    "for index, value in enumerate(predicted_percentages):\n",
    "    ax2.text(index + offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Count the occurrences of each class in the real data\n",
    "real_counts = np.bincount(realtest_y)\n",
    "total_real = sum(real_counts)  # Total count for real data\n",
    "\n",
    "# Count the occurrences of each class in the predicted data\n",
    "predicted_counts = np.bincount(y_pred)\n",
    "total_predicted = sum(predicted_counts)  # Total count for predicted data\n",
    "\n",
    "# Convert counts to percentages\n",
    "real_percentages = [count / total_real * 100 for count in real_counts]\n",
    "predicted_percentages = [count / total_predicted * 100 for count in predicted_counts]\n",
    "\n",
    "# Class names\n",
    "categories = ['Ground Truth', 'Predicted']\n",
    "female_male_labels = ['Female', 'Male']\n",
    "\n",
    "# Custom colors\n",
    "colors = ['lightpink', 'lightblue']\n",
    "\n",
    "# Bar width and offset\n",
    "bar_width = 0.3\n",
    "offset = 0.15\n",
    "\n",
    "plt.figure(figsize=(4, 2.83))\n",
    "\n",
    "# Creating the bar plots\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "# Bars for Female and Male in each category\n",
    "for i, label in enumerate(female_male_labels):\n",
    "    ax.bar(np.arange(len(categories)) + offset * (2 * i - 1), \n",
    "           [real_percentages[i], predicted_percentages[i]], \n",
    "           width=bar_width, \n",
    "           color=colors[i], \n",
    "           label=label)\n",
    "\n",
    "# Add some text for labels, title and axes ticks\n",
    " \n",
    "ax.set_ylabel('Percentage', fontsize=12)\n",
    "ax.set_xticks(np.arange(len(categories)))\n",
    "ax.set_xticklabels(categories, fontsize=12)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# Move the legend to the right of the plot\n",
    "ax.legend(  loc='upper left', bbox_to_anchor=(1.05, 1), fontsize=12, borderaxespad=0.)\n",
    "\n",
    "# Add percentages above the bars\n",
    "for i, label in enumerate(female_male_labels):\n",
    "    for index in np.arange(len(categories)):\n",
    "        percentage = real_percentages[i] if index == 0 else predicted_percentages[i]\n",
    "        ax.text(index + offset * (2 * i - 1), percentage, f'{percentage:.1f}', ha='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Define model\n",
    "model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=400,  # set large n_estimators but use early_stopping\n",
    "    learning_rate=0.1,\n",
    "    max_depth=10,\n",
    "    random_state=551\n",
    ")\n",
    "\n",
    "# Assuming full_X_train, full_Y_train, and extracted_columns_1 are already defined\n",
    "scaler = StandardScaler()\n",
    "full_X_train_scaled = scaler.fit_transform(full_X_train)\n",
    "extracted_columns_1_scaled = scaler.transform(extracted_columns_1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(full_X_train_scaled, full_Y_train)\n",
    "y_prob = model.predict_proba(extracted_columns_1_scaled)[:, 1]\n",
    "y_pred = model.predict(extracted_columns_1_scaled).astype(int)  # Save the predicted labels\n",
    "\n",
    "# Save the XGBoost predicted labels to a CSV file\n",
    "y_pred_df = pd.DataFrame({'XGBoost_Predicted_Labels': y_pred})\n",
    "y_pred_df.to_csv('xgboost_predicted_labels_extracted_columns_1.csv', index=False)\n",
    "\n",
    "# Calculate the 0 to 1 ratio\n",
    "zero_count = np.sum(y_pred == 0)\n",
    "one_count = np.sum(y_pred == 1)\n",
    "ratio_0_to_1 = zero_count / one_count if one_count != 0 else 'Undefined (no 1s predicted)'\n",
    "\n",
    "print(f'0 to 1 ratio: {ratio_0_to_1}')\n",
    "\n",
    "# Count the occurrences of each class in the predicted data\n",
    "predicted_counts = np.bincount(y_pred)\n",
    "predicted_percentages = (predicted_counts / predicted_counts.sum()) * 100\n",
    "\n",
    "# Class names\n",
    "classes = ['Female', 'Male']\n",
    "class_indices = np.arange(len(classes))\n",
    "\n",
    "# Bar width and offset\n",
    "bar_width = 0.3  # Bar width\n",
    "offset = 0.15  # Offset for moving bars closer\n",
    "\n",
    "plt.figure(figsize=(5.1, 2.545))\n",
    "\n",
    "# Plot for Predicted Data\n",
    "ax2 = plt.subplot(1, 1, 1)\n",
    "ax2.bar(class_indices + offset, predicted_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax2.set_title('Predicted Sex', fontsize=12)\n",
    "ax2.set_xlabel('Gender', fontsize=12)\n",
    "ax2.set_ylabel('Percentage', fontsize=12)\n",
    "ax2.set_xticks(class_indices)\n",
    "ax2.set_xticklabels(classes, fontsize=12)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax2.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the predicted data plot\n",
    "for index, value in enumerate(predicted_percentages):\n",
    "    ax2.text(index + offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Define model\n",
    "model =    XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "        learning_rate=0.05,\n",
    "        max_depth=10,random_state=551\n",
    "    )\n",
    "# Assuming full_X_train, full_Y_train, and extracted_columns_1 are already defined\n",
    "scaler = StandardScaler()\n",
    "full_X_train_scaled = scaler.fit_transform(full_X_train)\n",
    "extracted_columns_1_scaled = scaler.transform(extracted_columns_1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(full_X_train_scaled, full_Y_train)\n",
    "y_prob = model.predict_proba(extracted_columns_1_scaled)[:, 1]\n",
    "y_pred = model.predict(extracted_columns_1_scaled).astype(int)  # Save the predicted labels\n",
    "\n",
    "# Save the XGBoost predicted labels to a CSV file\n",
    "y_pred_df = pd.DataFrame({'XGBoost_Predicted_Labels': y_pred})\n",
    "y_pred_df.to_csv('xgboost_predicted_labels_extracted_columns_1.csv', index=False)\n",
    "\n",
    "# Calculate the 0 to 1 ratio\n",
    "zero_count = np.sum(y_pred == 0)\n",
    "one_count = np.sum(y_pred == 1)\n",
    "ratio_0_to_1 = zero_count / one_count if one_count != 0 else 'Undefined (no 1s predicted)'\n",
    "\n",
    "print(f'0 to 1 ratio: {ratio_0_to_1}')\n",
    "\n",
    "# Count the occurrences of each class in the predicted data\n",
    "predicted_counts = np.bincount(y_pred)\n",
    "predicted_percentages = (predicted_counts / predicted_counts.sum()) * 100\n",
    "\n",
    "# Class names\n",
    "classes = ['Female', 'Male']\n",
    "class_indices = np.arange(len(classes))\n",
    "\n",
    "# Bar width and offset\n",
    "bar_width = 0.3  # Bar width\n",
    "offset = 0.15  # Offset for moving bars closer\n",
    "\n",
    "plt.figure(figsize=(5.1, 2.545))\n",
    "\n",
    "# Plot for Predicted Data\n",
    "ax2 = plt.subplot(1, 1, 1)\n",
    "ax2.bar(class_indices + offset, predicted_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax2.set_title('Predicted Sex', fontsize=12)\n",
    "ax2.set_xlabel('Gender', fontsize=12)\n",
    "ax2.set_ylabel('Percentage', fontsize=12)\n",
    "ax2.set_xticks(class_indices)\n",
    "ax2.set_xticklabels(classes, fontsize=12)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax2.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the predicted data plot\n",
    "for index, value in enumerate(predicted_percentages):\n",
    "    ax2.text(index + offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Define model\n",
    "model =    XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "        learning_rate=0.05,\n",
    "        max_depth=10,random_state=551\n",
    "    )\n",
    "# Assuming full_X_train, full_Y_train, and extracted_columns_1 are already defined\n",
    "scaler = StandardScaler()\n",
    "full_X_train_scaled = scaler.fit_transform(full_X_train)\n",
    "extracted_columns_1_scaled = scaler.transform(extracted_columns_1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(full_X_train_scaled, full_Y_train)\n",
    "y_prob = model.predict_proba(extracted_columns_1_scaled)[:, 1]\n",
    "y_pred = model.predict(extracted_columns_1_scaled).astype(int)  # Save the predicted labels\n",
    "\n",
    "# Save the XGBoost predicted labels to a CSV file\n",
    "y_pred_df = pd.DataFrame({'XGBoost_Predicted_Labels': y_pred})\n",
    "y_pred_df.to_csv('xgboost_predicted_labels_extracted_columns_1.csv', index=False)\n",
    "\n",
    "# Calculate the 0 to 1 ratio\n",
    "zero_count = np.sum(y_pred == 0)\n",
    "one_count = np.sum(y_pred == 1)\n",
    "ratio_0_to_1 = zero_count / one_count if one_count != 0 else 'Undefined (no 1s predicted)'\n",
    "\n",
    "print(f'0 to 1 ratio: {ratio_0_to_1}')\n",
    "\n",
    "# Count the occurrences of each class in the predicted data\n",
    "predicted_counts = np.bincount(y_pred)\n",
    "predicted_percentages = (predicted_counts / predicted_counts.sum()) * 100\n",
    "\n",
    "# Class names\n",
    "classes = ['Female', 'Male']\n",
    "class_indices = np.arange(len(classes))\n",
    "\n",
    "# Bar width and offset\n",
    "bar_width = 0.3  # Bar width\n",
    "offset = 0.15  # Offset for moving bars closer\n",
    "\n",
    "plt.figure(figsize=(5.1, 2.545))\n",
    "\n",
    "# Plot for Predicted Data\n",
    "ax2 = plt.subplot(1, 1, 1)\n",
    "ax2.bar(class_indices + offset, predicted_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax2.set_title('Predicted Sex', fontsize=12)\n",
    "ax2.set_xlabel('Gender', fontsize=12)\n",
    "ax2.set_ylabel('Percentage', fontsize=12)\n",
    "ax2.set_xticks(class_indices)\n",
    "ax2.set_xticklabels(classes, fontsize=12)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax2.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the predicted data plot\n",
    "for index, value in enumerate(predicted_percentages):\n",
    "    ax2.text(index + offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set global font properties\n",
    "rcParams['font.family'] = 'Arial'\n",
    "rcParams['font.size'] = 7\n",
    "rcParams['font.weight'] = 'normal'\n",
    "\n",
    "# Define model\n",
    "model =  XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "    learning_rate=0.18,\n",
    "    max_depth=7,random_seed=551\n",
    ")\n",
    "# model =  XGBClassifier(\n",
    "#     use_label_encoder=False,\n",
    "#     eval_metric='logloss',\n",
    "#     n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "#     learning_rate=0.18,\n",
    "#     max_depth=7\n",
    "# )\n",
    "# Dummy data setup (replace with actual data loading)\n",
    "# full_X_train, full_Y_train = np.random.rand(100, 10), np.random.randint(0, 2, 100)\n",
    "# realtest, realtest_y = np.random.rand(50, 10), np.random.randint(0, 2, 50)\n",
    "scaler = StandardScaler()\n",
    "full_X_train_scaled = scaler.fit_transform(full_X_train)\n",
    "realtest_scaled = scaler.transform(realtest)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(full_X_train_scaled, full_Y_train)\n",
    "y_prob = model.predict_proba(realtest_scaled)[:, 1]\n",
    "y_pred = model.predict(realtest_scaled).astype(int)  # Save the predicted labels\n",
    "\n",
    "# Calculate AUROC and AUPRC\n",
    "roc_auc = roc_auc_score(realtest_y, y_prob)\n",
    "pr_auc = average_precision_score(realtest_y, y_prob)\n",
    "\n",
    "print(f'AUROC: {roc_auc:.4f}')\n",
    "print(f'AUPRC: {pr_auc:.4f}')\n",
    "\n",
    "# Save the XGBoost predicted labels to a CSV file\n",
    "y_pred_df = pd.DataFrame({'XGBoost_Predicted_Labels': y_pred})\n",
    "y_pred_df.to_csv('xgboost_predicted_labels.csv', index=False)\n",
    "\n",
    "# Bar plot for real and predicted data\n",
    "# Count the occurrences of each class in the real data\n",
    "real_counts = np.bincount(realtest_y)\n",
    "real_percentages = (real_counts / real_counts.sum()) * 100\n",
    "\n",
    "# Count the occurrences of each class in the predicted data\n",
    "predicted_counts = np.bincount(y_pred)\n",
    "predicted_percentages = (predicted_counts / predicted_counts.sum()) * 100\n",
    "\n",
    "# Class names\n",
    "classes = ['Female', 'Male']\n",
    "class_indices = np.arange(len(classes))\n",
    "\n",
    "# Bar width and offset\n",
    "bar_width = 0.3  # Bar width\n",
    "offset = 0.15  # Offset for moving bars closer\n",
    "\n",
    "plt.figure(figsize=(5.1, 2.545))\n",
    "\n",
    "# Plot for Real Data\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.bar(class_indices - offset, real_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax1.set_title('Ground Truth Sex', fontsize=12)\n",
    "ax1.set_xlabel('Gender', fontsize=12)\n",
    "ax1.set_ylabel('Percentage', fontsize=12)\n",
    "ax1.set_xticks(class_indices)\n",
    "ax1.set_xticklabels(classes, fontsize=12)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax1.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the real data plot\n",
    "for index, value in enumerate(real_percentages):\n",
    "    ax1.text(index - offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "# Plot for Predicted Data\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.bar(class_indices + offset, predicted_percentages, width=bar_width, color=['lightpink', 'lightblue'])\n",
    "ax2.set_title('Predicted Sex', fontsize=12)\n",
    "ax2.set_xlabel('Gender', fontsize=12)\n",
    "ax2.set_ylabel('Percentage', fontsize=12)\n",
    "ax2.set_xticks(class_indices)\n",
    "ax2.set_xticklabels(classes, fontsize=12)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax2.grid(False)  # Disable grid\n",
    "\n",
    "# Add percentages above the bars in the predicted data plot\n",
    "for index, value in enumerate(predicted_percentages):\n",
    "    ax2.text(index + offset, value - 5, f'{value:.1f}%', color='black', ha=\"center\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Count the occurrences of each class in the real data\n",
    "real_counts = np.bincount(realtest_y)\n",
    "\n",
    "# Count the occurrences of each class in the predicted data\n",
    "predicted_counts = np.bincount(y_test_pred)\n",
    "\n",
    "# Class names\n",
    "classes = ['Female', 'Male']\n",
    "class_indices = np.arange(len(classes))\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.35  # Adjust this value to change the bar width\n",
    "\n",
    "# Offset for moving bars closer\n",
    "offset = 0.17  # Adjust this value to move bars closer or farther\n",
    "\n",
    "# Colors\n",
    "light_pink = '#FFB6C1'\n",
    "light_blue = '#ADD8E6'\n",
    "\n",
    "# Creating the bar plots\n",
    "plt.figure(figsize=(7.09, 6.69/2))\n",
    "\n",
    "# Plot for Real Data\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "plt.bar(class_indices - offset, real_counts, width=bar_width, color=[light_pink, light_blue])\n",
    "plt.title('Ground Truth Sex')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(class_indices, classes)\n",
    "\n",
    "# Add counts above the bars in the real data plot\n",
    "for index, value in enumerate(real_counts):\n",
    "    plt.text(index - offset, value, str(value), color='black', ha=\"center\")\n",
    "\n",
    "# Plot for Predicted Data\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "plt.bar(class_indices - offset, predicted_counts, width=bar_width, color=[light_pink, light_blue])\n",
    "plt.title('Predicted Sex')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(class_indices, classes)\n",
    "\n",
    "# Add counts above the bars in the predicted data plot\n",
    "for index, value in enumerate(predicted_counts):\n",
    "    plt.text(index - offset, value, str(value), color='black', ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hhhh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(full_X_train, full_Y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = rf_regressor.predict(extracted_columns_1)\n",
    " \n",
    "# Convert the array to a pandas DataFrame\n",
    "df = pd.DataFrame(y_pred)\n",
    "df.to_csv('adata_matrix.csv', index=False)\n",
    "count_greater_than_05 = sum(1 for element in y_pred if element >= 0.5)\n",
    "\n",
    "# Calculate percentage\n",
    "percentage = (count_greater_than_05 / len(y_pred)) * 100\n",
    "percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform it\n",
    "scaled_X_train = scaler.fit_transform(full_X_train)\n",
    "\n",
    "# Scale the test data (do not fit the scaler again on test data)\n",
    "scaled_X_test = scaler.transform(extracted_columns_1)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Fit the model on the scaled training data\n",
    "xgb_classifier.fit(scaled_X_train, full_Y_train)\n",
    "\n",
    "# Predict on scaled test data\n",
    "y_pred = xgb_classifier.predict(scaled_X_test)\n",
    "\n",
    "# Convert the array to a pandas DataFrame\n",
    "df = pd.DataFrame(y_pred)\n",
    "df.to_csv('adata_matrix.csv', index=False)\n",
    "\n",
    "# Count how many predictions are 1 (assuming 1 represents the class of interest)\n",
    "count_greater_than_05 = sum(1 for element in y_pred if element == 1)\n",
    "\n",
    "# Calculate percentage\n",
    "percentage = (count_greater_than_05 / len(y_pred)) * 100\n",
    "print(percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform the training data\n",
    "full_X_train_scaled = scaler.fit_transform(full_X_train)\n",
    "\n",
    "# Transform the test data using the same scaler\n",
    "extracted_columns_1_scaled = scaler.transform(extracted_columns_1)\n",
    "extracted_columns_2_scaled = scaler.transform(extracted_columns_2)\n",
    "extracted_columns_3_scaled = scaler.transform(extracted_columns_3)\n",
    "extracted_columns_4_scaled = scaler.transform(extracted_columns_4)\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "rf_regressor =  XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=100,  # set large n_estimators but use early_stopping\n",
    "    learning_rate=0.18,\n",
    "    max_depth=7,random_seed=551\n",
    ")\n",
    "rf_regressor.fit(full_X_train_scaled, full_Y_train)\n",
    "\n",
    "# Lists to store percentages and labels\n",
    "percentages = []\n",
    "labels = ['WT_WT', 'mdx_WT', 'WT_mdx', 'mdx_mdx']\n",
    "\n",
    "# Loop through each test dataset\n",
    "for extracted_columns_scaled in [extracted_columns_1_scaled, extracted_columns_2_scaled, extracted_columns_3_scaled, extracted_columns_4_scaled]:\n",
    "    # Predict on test data\n",
    "    y_pred = rf_regressor.predict(extracted_columns_scaled)\n",
    "\n",
    "    # Calculate the percentage of predictions >= 0.5\n",
    "    count_greater_than_05 = sum(1 for element in y_pred if element > 0.5)\n",
    "    percentage = (count_greater_than_05 / len(y_pred)) * 100\n",
    "    percentages.append(percentage)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df = pd.DataFrame({'Condition': labels, 'Percentage': percentages})\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(df['Condition'], df['Percentage'], color='skyblue')\n",
    "\n",
    "# Adding the numbers on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), va='bottom')  # Adjust alignment as needed\n",
    "\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.title('Percentage of Predictions ≥ 0.5 by Condition')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(full_X_train, full_Y_train)\n",
    "\n",
    "# Lists to store percentages and labels\n",
    "percentages = []\n",
    "labels = ['WT_WT', 'mdx_WT', 'WT_mdx', 'mdx_mdx']\n",
    "\n",
    "# Loop through each test dataset\n",
    "for extracted_columns in [extracted_columns_1, extracted_columns_2, extracted_columns_3, extracted_columns_4]:\n",
    "    # Predict on test data\n",
    "    y_pred = rf_regressor.predict(extracted_columns)\n",
    "\n",
    "    # Calculate the percentage of predictions >= 0.5\n",
    "    count_greater_than_05 = sum(1 for element in y_pred if element > 0.5)\n",
    "    percentage = (count_greater_than_05 / len(y_pred)) * 100\n",
    "    percentages.append(percentage)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df = pd.DataFrame({'Condition': labels, 'Percentage': percentages})\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(df['Condition'], df['Percentage'], color='skyblue')\n",
    "\n",
    "# Adding the numbers on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), va='bottom')  # Adjust alignment as needed\n",
    "\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.title('Percentage of Predictions ≥ 0.5 by Condition')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(full_X_train, full_Y_train)\n",
    "\n",
    "# Lists to store percentages and labels\n",
    "percentages = []\n",
    "labels = ['WT_WT', 'mdx_WT', 'WT_mdx', 'mdx_mdx']\n",
    "\n",
    "# Loop through each test dataset\n",
    "for extracted_columns in [extracted_columns_1, extracted_columns_2, extracted_columns_3, extracted_columns_4]:\n",
    "    # Predict on test data\n",
    "    y_pred = rf_regressor.predict(extracted_columns)\n",
    "\n",
    "    # Calculate the percentage of predictions >= 0.5\n",
    "    count_greater_than_05 = sum(1 for element in y_pred if element > 0.5)\n",
    "    percentage = (count_greater_than_05 / len(y_pred)) * 100\n",
    "    percentages.append(percentage)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df = pd.DataFrame({'Condition': labels, 'Percentage': percentages})\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(df['Condition'], df['Percentage'], color='skyblue')\n",
    "\n",
    "# Adding the numbers on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), va='bottom')  # Adjust alignment as needed\n",
    "\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.title('Percentage of Predictions ≥ 0.5 by Condition')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initialize and fit the scaler and classifier (as in your previous code)\n",
    "# ...\n",
    "\n",
    "# Assuming percentages and labels have been computed as before\n",
    "df = pd.DataFrame({'Condition': labels, 'Percentage': percentages})\n",
    "\n",
    "# Prepare data for plotting\n",
    "conditions = df['Condition']\n",
    "percentages = df['Percentage']\n",
    "\n",
    "# Plot settings\n",
    "bar_width = 0.6\n",
    "opacity = 0.8\n",
    "\n",
    "# Creating the bar plot\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(conditions, percentages, bar_width, alpha=opacity, color='lightblue')\n",
    "\n",
    "# Adding the numbers on top of the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), va='bottom')\n",
    "\n",
    "# Add some text for labels, title and axes ticks\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_ylabel('Percentage (%)')\n",
    "ax.set_title('Percentage of Class 1 Predictions by Condition')\n",
    "ax.set_xticks(np.arange(len(conditions)))\n",
    " \n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
