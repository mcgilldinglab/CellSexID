{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4635b360",
   "metadata": {},
   "source": [
    "# CellSexID: Human Single-Cell Sex Prediction Analysis\n",
    "\n",
    "This notebook demonstrates comprehensive sex prediction across multiple human single-cell RNA-seq datasets using machine learning approaches. We analyze four main datasets to validate the robustness and generalizability of sex classification methods:\n",
    "\n",
    "## Datasets Analyzed\n",
    "1. **Data1 ATL Dataset (GSE294224)**: Adult T-cell leukemia-lymphoma samples\n",
    "2. **Kidney Dataset (GSE151671)**: Donor kidney cells for transplant analysis  \n",
    "3. **Data2 (AML/MLL Dataset, GSE289435)**: Bone marrow mononuclear cells from AML patients\n",
    "4. **Data3 (Thymic Dataset, GSE262749)**: Medullary thymic epithelial cells\n",
    "\n",
    "All datasets in this analysis undergo identical preprocessing steps to ensure standardized and comparable results across different studies:\n",
    "\n",
    "### **Standardized Quality Control & Preprocessing:**\n",
    "\n",
    "1. **Gene Filtering**: `min_cells = 3` - Remove genes expressed in fewer than 3 cells\n",
    "2. **Cell Filtering**: `min_genes = 200` - Remove cells expressing fewer than 200 genes  \n",
    "3. **Mitochondrial Filtering**: `mt < 5%` - Remove cells with >5% mitochondrial gene expression\n",
    "4. **Normalization**: `target_sum = 1e4` - Library-size normalize to 10,000 counts per cell\n",
    "5. **Log Transformation**: `log1p` - Apply log(x + 1) transformation\n",
    "\n",
    "\n",
    "## Methodology Overview\n",
    "- **Feature Selection**: Sex-specific marker genes from X/Y chromosomes\n",
    "- **Models**: Logistic Regression, Linear SVM, XGBoost, Random Forest\n",
    "- **Validation Strategy**: Cross-dataset validation and statistical robustness testing\n",
    "- **Performance Metrics**: AUROC, AUPRC, accuracy, precision, recall, F1-score\n",
    "\n",
    "## Key Contributions\n",
    "- Cross-dataset generalization analysis\n",
    "- Optimal marker gene panel identification\n",
    "- Statistical validation with multiple random seeds\n",
    "- Performance comparison across tissue types and disease states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf5b2f9",
   "metadata": {},
   "source": [
    "## Dataset 1: ATL (Adult T-cell Leukemia-Lymphoma) Analysis\n",
    "\n",
    "## Data Processing and Quality Control\n",
    "Processing of three 10X Genomics datasets (ATL1, ATL2, ATL3) from adult T-cell leukemia-lymphoma samples. This analysis includes data loading, quality control filtering, and preparation for downstream sex prediction modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a569ced6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Loading ATL1\n",
      "â€¢ Successfully loaded ATL1: 5066 cells Ã— 36610 genes\n",
      "â€¢ Loading ATL2\n",
      "â€¢ Successfully loaded ATL2: 10151 cells Ã— 36610 genes\n",
      "â€¢ Loading ATL3\n",
      "â€¢ Successfully loaded ATL3: 5095 cells Ã— 36610 genes\n",
      "â€¢ Concatenating datasets\n",
      "â€¢ Concatenated: 20,312 cells Ã— 36,610 genes\n",
      "â€¢ Performing QC and filtering\n",
      "â€¢ Normalizing data\n",
      "â€¢ Writing to data/human_1/atl_merged_qc.h5ad\n",
      "âœ… Finished:\n",
      "   Cells  : 9,292\n",
      "   Genes  : 22,630\n",
      "   Sex    :\n",
      "sex\n",
      "male      6481\n",
      "female    2811\n",
      "Name: count, dtype: int64\n",
      "   Samples:\n",
      "sample\n",
      "ATL2    3982\n",
      "ATL1    2811\n",
      "ATL3    2499\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "ATL scRNA-seq merge + QC â€¢ GSE294224\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "- Load three 10X Genomics datasets (ATL1, ATL2, ATL3)\n",
    "- Prefix barcodes with sample name\n",
    "- Concatenate matrices\n",
    "- Assign sex labels based on patient information\n",
    "- Perform QC filtering (min_genes, mitochondrial content)\n",
    "- Library-size normalize, log1p transform\n",
    "- Save sparse .h5ad\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio  # Correct import for mmread\n",
    "import sys\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ USER PATHS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DATA_DIR = \"data/GSE294224_RAW\"\n",
    "OUTDIR = \"data/human_1\"\n",
    "OUTFILE = os.path.join(OUTDIR, \"atl_merged_qc.h5ad\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# Sample information\n",
    "samples = [\"ATL1\", \"ATL2\", \"ATL3\"]\n",
    "# Sex labels according to your data\n",
    "sex_labels = {\"ATL1\": \"female\", \"ATL2\": \"male\", \"ATL3\": \"male\"}\n",
    "\n",
    "VERBOSE = True  # one-line progress prints\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def load_10x_data(sample: str, data_dir: str) -> sc.AnnData:\n",
    "    \"\"\"Load one 10X Genomics dataset using direct file loading.\"\"\"\n",
    "    if VERBOSE: print(f\"â€¢ Loading {sample}\")\n",
    "    \n",
    "    # Define file patterns based on the actual directory listing\n",
    "    sample_id_mapping = {\n",
    "        \"ATL1\": \"8900566\",\n",
    "        \"ATL2\": \"8900568\",\n",
    "        \"ATL3\": \"8900570\"\n",
    "    }\n",
    "    \n",
    "    sample_id = sample_id_mapping[sample]\n",
    "    \n",
    "    # Correct file paths based on your directory listing\n",
    "    matrix_file = os.path.join(data_dir, f\"GSM{sample_id}_{sample}_matrix.mtx.gz\")\n",
    "    features_file = os.path.join(data_dir, f\"GSM{sample_id}_{sample}_features.tsv.gz\")\n",
    "    barcodes_file = os.path.join(data_dir, f\"GSM{sample_id}_{sample}_barcodes.tsv.gz\")\n",
    "    \n",
    "    # Check if files exist\n",
    "    for file_path in [matrix_file, features_file, barcodes_file]:\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Load matrix - using the correct scipy.io module\n",
    "        X = spio.mmread(matrix_file).T.tocsr()\n",
    "        \n",
    "        # Load features (genes)\n",
    "        features = pd.read_csv(features_file, sep='\\t', header=None)\n",
    "        if features.shape[1] >= 2:\n",
    "            # The second column typically contains gene symbols\n",
    "            gene_names = features[1].values\n",
    "        else:\n",
    "            # If there's only one column, use it as both ID and name\n",
    "            gene_names = features[0].values\n",
    "        \n",
    "        # Make gene names unique\n",
    "        gene_names_unique = make_unique_names(gene_names)\n",
    "        \n",
    "        # Load barcodes\n",
    "        barcodes = pd.read_csv(barcodes_file, sep='\\t', header=None)[0].values\n",
    "        \n",
    "        # Create AnnData object\n",
    "        adata = sc.AnnData(X=X)\n",
    "        adata.obs_names = [f\"{sample}_{bc}\" for bc in barcodes]\n",
    "        adata.var_names = gene_names_unique\n",
    "        \n",
    "        # Add sample and sex information\n",
    "        adata.obs[\"sample\"] = sample\n",
    "        adata.obs[\"sex\"] = sex_labels[sample]\n",
    "        \n",
    "        return adata\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {sample}: {e}\")\n",
    "        return None\n",
    "\n",
    "def make_unique_names(names):\n",
    "    \"\"\"Make duplicate names unique by appending numbers.\"\"\"\n",
    "    name_counts = {}\n",
    "    unique_names = []\n",
    "    \n",
    "    for name in names:\n",
    "        if name in name_counts:\n",
    "            name_counts[name] += 1\n",
    "            unique_names.append(f\"{name}_{name_counts[name]}\")\n",
    "        else:\n",
    "            name_counts[name] = 0\n",
    "            unique_names.append(name)\n",
    "    \n",
    "    return unique_names\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) LOAD ALL SAMPLES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "adatas = []\n",
    "for sample in samples:\n",
    "    adata = load_10x_data(sample, DATA_DIR)\n",
    "    if adata is not None:\n",
    "        adatas.append(adata)\n",
    "        if VERBOSE:\n",
    "            print(f\"â€¢ Successfully loaded {sample}: {adata.n_obs} cells Ã— {adata.n_vars} genes\")\n",
    "    else:\n",
    "        print(f\"âŒ Failed to load {sample}\")\n",
    "\n",
    "# Check if we have data to work with\n",
    "if not adatas:\n",
    "    print(\"No data was successfully loaded. Exiting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) CONCATENATE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if VERBOSE: print(\"â€¢ Concatenating datasets\")\n",
    "if len(adatas) == 1:\n",
    "    # If only one dataset was loaded, skip concatenation\n",
    "    adata = adatas[0].copy()\n",
    "    print(\"Only one dataset was loaded, skipping concatenation\")\n",
    "else:\n",
    "    # Concatenate multiple datasets\n",
    "    adata = sc.concat(\n",
    "        adatas,\n",
    "        join=\"outer\",     # Union of genes\n",
    "        merge=\"first\",\n",
    "        fill_value=0,     # Fill gaps with 0\n",
    "    )\n",
    "\n",
    "# Ensure the data is sparse\n",
    "if not sp.issparse(adata.X):\n",
    "    adata.X = sp.csr_matrix(adata.X)\n",
    "\n",
    "if VERBOSE:\n",
    "    print(f\"â€¢ Concatenated: {adata.n_obs:,} cells Ã— {adata.n_vars:,} genes\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) BASIC QC & FILTERING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if VERBOSE: print(\"â€¢ Performing QC and filtering\")\n",
    "\n",
    "# Filter genes with low expression\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "# Filter cells with few expressed genes\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "\n",
    "# Identify mitochondrial genes (human MT genes start with MT-)\n",
    "adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "\n",
    "# Calculate QC metrics\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\"], inplace=True)\n",
    "\n",
    "# Filter cells with high mitochondrial content\n",
    "max_mito_percent = 5\n",
    "adata = adata[adata.obs[\"pct_counts_mt\"] < max_mito_percent, :].copy()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) NORMALIZATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if VERBOSE: print(\"â€¢ Normalizing data\")\n",
    "sc.pp.normalize_total(adata, target_sum=1e4, inplace=True)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5) WRITE OUTPUT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if VERBOSE: print(f\"â€¢ Writing to {OUTFILE}\")\n",
    "adata.write(OUTFILE, compression=\"gzip\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SUMMARY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"âœ… Finished:\")\n",
    "print(f\"   Cells  : {adata.n_obs:,}\")\n",
    "print(f\"   Genes  : {adata.n_vars:,}\")\n",
    "print(\"   Sex    :\")\n",
    "print(adata.obs[\"sex\"].value_counts(dropna=False))\n",
    "print(\"   Samples:\")\n",
    "print(adata.obs[\"sample\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f555e",
   "metadata": {},
   "source": [
    "## Cross-Dataset Validation: Data2(MLL) â†’ Data1(ATL)\n",
    "**Training Data**: Data2 (MLL/AML dataset, GSE289435) - Subsample\n",
    "**Testing Data**: ATL dataset (GSE294224) - Data1\n",
    "\n",
    "Training sex classification models on bone marrow mononuclear cells (Data2) and testing on adult T-cell leukemia-lymphoma samples (ATL/Data1). This cross-dataset validation tests generalizability from AML to ATL disease contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2febe7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MLL dataset (training data)...\n",
      "Renaming 15 genes using alias dictionary\n",
      "MLL dataset: 87,171 cells  (â™€ 44716  â™‚ 42455)\n",
      "\n",
      "Loading ATL dataset (test data)...\n",
      "Renaming 15 genes using alias dictionary\n",
      "ATL dataset: 9,292 cells  (â™€ 2811  â™‚ 6481)\n",
      "\n",
      "Extracting 1/15 random subsample from MLL dataset...\n",
      "Training subsample: 5,811 cells  (â™€ 2981  â™‚ 2830)\n",
      "Subsampling ratio: 6.7% of original MLL data\n",
      "\n",
      "Extracting selected marker genes from training data...\n",
      "Markers used (9): ['RPS4Y1', 'EIF1AY', 'Xist', 'Ddx3y', 'Uty', 'Kdm5d', 'IFIT3', 'IFIT2', 'RPS4X']\n",
      "\n",
      "Extracting selected marker genes from test data...\n",
      "Markers used (9): ['RPS4Y1', 'EIF1AY', 'Xist', 'Ddx3y', 'Uty', 'Kdm5d', 'IFIT3', 'IFIT2', 'RPS4X']\n",
      "\n",
      "Common markers used for training and testing (9): ['Ddx3y', 'EIF1AY', 'IFIT2', 'IFIT3', 'Kdm5d', 'RPS4X', 'RPS4Y1', 'Uty', 'Xist']\n",
      "\n",
      "==================================================\n",
      "Training and evaluating models using selected genes\n",
      "==================================================\n",
      "\n",
      "=== LogisticRegression ===\n",
      " TRAIN â†’ Acc=0.8954, F1=0.8816, AUROC=0.9615, AUPRC=0.9641\n",
      " TEST â†’ Acc=0.9523, F1=0.9647, AUROC=0.9884, AUPRC=0.9954\n",
      "  Confusion Matrix:\n",
      "[[2791   20]\n",
      " [ 423 6058]]\n",
      "\n",
      "=== LinearSVC ===\n",
      " TRAIN â†’ Acc=0.8945, F1=0.8805, AUROC=0.9615, AUPRC=0.9643\n",
      " TEST â†’ Acc=0.9534, F1=0.9655, AUROC=0.9881, AUPRC=0.9953\n",
      "  Confusion Matrix:\n",
      "[[2801   10]\n",
      " [ 423 6058]]\n",
      "\n",
      "=== XGBoost ===\n",
      " TRAIN â†’ Acc=0.9191, F1=0.9182, AUROC=0.9838, AUPRC=0.9837\n",
      " TEST â†’ Acc=0.8797, F1=0.9179, AUROC=0.9802, AUPRC=0.9922\n",
      "  Confusion Matrix:\n",
      "[[1923  888]\n",
      " [ 230 6251]]\n",
      "\n",
      "=== RandomForest ===\n",
      " TRAIN â†’ Acc=0.9210, F1=0.9200, AUROC=0.9843, AUPRC=0.9840\n",
      " TEST â†’ Acc=0.8783, F1=0.9171, AUROC=0.9812, AUPRC=0.9926\n",
      "  Confusion Matrix:\n",
      "[[1907  904]\n",
      " [ 227 6254]]\n",
      "\n",
      "Final results:\n",
      "                Model  Train_Acc  Train_F1  Train_AUROC  Train_AUPRC  \\\n",
      "0  LogisticRegression   0.895371  0.881620     0.961491     0.964143   \n",
      "1           LinearSVC   0.894510  0.880530     0.961468     0.964270   \n",
      "2             XGBoost   0.919119  0.918175     0.983814     0.983713   \n",
      "3        RandomForest   0.921012  0.919993     0.984268     0.983955   \n",
      "\n",
      "   Test_Acc   Test_F1  Test_AUROC  Test_AUPRC  \n",
      "0  0.952325  0.964726    0.988448    0.995441  \n",
      "1  0.953401  0.965495    0.988117    0.995308  \n",
      "2  0.879681  0.917915    0.980183    0.992181  \n",
      "3  0.878282  0.917076    0.981238    0.992564  \n",
      "\n",
      "All results saved to /Users/haley/Desktop/send_tooo/AAA_final/human2_human1_selected\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Sex classification using MLL data (human_2) subsample as training and ATL data (human_1) as testing\n",
    "Using 10 selected marker genes: RPS4Y1, EIF1AY, XIST, DDX3Y, UTY, KDM5D, IFIT3, IFIT2, RPS4X, RPL29\n",
    "Models: LogisticRegression, Linear-SVC, XGBoost, Random-Forest\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€ imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os, pathlib, warnings\n",
    "import numpy as np, pandas as pd, scanpy as sc, scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute            import SimpleImputer\n",
    "from sklearn.preprocessing     import StandardScaler\n",
    "from sklearn.pipeline          import Pipeline\n",
    "from sklearn.linear_model      import LogisticRegression\n",
    "from sklearn.svm               import SVC\n",
    "from sklearn.ensemble          import RandomForestClassifier\n",
    "from sklearn.model_selection   import train_test_split\n",
    "from xgboost                   import XGBClassifier\n",
    "from sklearn.metrics           import (\n",
    "    accuracy_score, f1_score, roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ selected marker panel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SELECTED_MARKERS =  [\n",
    "    \"RPS4Y1\", \n",
    "    \"EIF1AY\", \n",
    "    \"XIST\", \n",
    "    \"DDX3Y\", \n",
    "    \"UTY\", \n",
    "    \"KDM5D\", \n",
    "    \"IFIT3\", \n",
    "    \"IFIT2\", \n",
    "    \"RPS4X\"\n",
    "]\n",
    "\n",
    " \n",
    "# â”€â”€â”€ alias dictionary for gene name mapping â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "alias_to_official = {\n",
    "    \"XIST\":\"Xist\", \"RPS27RT\":\"Rps27rt\", \"DDX3Y\":\"Ddx3y\", \"RPL35\":\"Rpl35\",\n",
    "    \"EIF2S3Y\":\"Eif2s3y\", \"EIF2S3L\":\"Eif2s3y\", \"GM42418\":\"Gm42418\", \"UBA52\":\"Uba52\",\n",
    "    \"RPL36A-PS1\":\"Rpl36a-ps1\", \"KDM5D\":\"Kdm5d\", \"JARID1D\":\"Kdm5d\", \"WDR89\":\"Wdr89\",\n",
    "    \"UTY\":\"Uty\", \"LARS2\":\"Lars2\", \"AY036118\":\"AY036118\", \"RPL9-PS6\":\"Rpl9-ps6\", \"RPS27\":\"Rps27\",\n",
    "    \"RPS4Y1\":\"RPS4Y1\", \"EIF1AY\":\"EIF1AY\", \"IFIT3\":\"IFIT3\", \"IFIT2\":\"IFIT2\", \n",
    "    \"RPS4X\":\"RPS4X\", \"RPL29\":\"RPL29\", \n",
    "    # Keep human gene names as-is since both datasets are human\n",
    "}\n",
    "\n",
    "# â”€â”€â”€ file paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DATA_DIR = \"data\"\n",
    "MLL_H5AD = os.path.join(DATA_DIR, \"human_2/mll_merged_qc.h5ad\")\n",
    "ATL_H5AD = os.path.join(DATA_DIR, \"human_1/atl_merged_qc.h5ad\")  # Now using ATL as test data\n",
    "OUT_DIR = pathlib.Path(\"result/human2_human1_selected\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# â”€â”€â”€ helper functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def unify_gene_symbols(adata):\n",
    "    \"\"\"Normalize gene symbols using alias dictionary\"\"\"\n",
    "    if not isinstance(adata.var_names, pd.Index):\n",
    "        return adata\n",
    "    \n",
    "    # Create a mapping dictionary for renaming\n",
    "    rename_dict = {}\n",
    "    for gene in adata.var_names:\n",
    "        # Check for aliases (case insensitive)\n",
    "        gene_upper = gene.upper()\n",
    "        if gene_upper in alias_to_official:\n",
    "            rename_dict[gene] = alias_to_official[gene_upper]\n",
    "    \n",
    "    # Rename genes if aliases are found\n",
    "    if rename_dict:\n",
    "        print(f\"Renaming {len(rename_dict)} genes using alias dictionary\")\n",
    "        adata.var_names = [rename_dict.get(g, g) for g in adata.var_names]\n",
    "        \n",
    "    # Make variable names unique if needed\n",
    "    if not adata.var_names.is_unique:\n",
    "        print(\"Making gene names unique\")\n",
    "        adata.var_names_make_unique()\n",
    "        \n",
    "    return adata\n",
    "\n",
    "def extract_sex_labels(adata):\n",
    "    \"\"\"Extract standardized sex labels (0=female, 1=male)\"\"\"\n",
    "    if \"sex\" not in adata.obs:\n",
    "        raise ValueError(\"'sex' column not found in AnnData.\")\n",
    "\n",
    "    sex = (\n",
    "        adata.obs[\"sex\"]\n",
    "          .astype(str).str.strip().str.lower()\n",
    "          .map({\"female\": 0, \"male\": 1})\n",
    "    )\n",
    "    mask = sex.notna()\n",
    "    return adata[mask].copy(), sex[mask].astype(int).values\n",
    "\n",
    "def make_pipe(clf):\n",
    "    \"\"\"Create a preprocessing pipeline for a classifier\"\"\"\n",
    "    steps = [(\"imp\", SimpleImputer(strategy=\"median\"))]\n",
    "    if isinstance(clf, (LogisticRegression, SVC)):\n",
    "        steps.append((\"sc\", StandardScaler(with_mean=False)))\n",
    "    steps.append((\"clf\", clf))\n",
    "    return Pipeline(steps)\n",
    "\n",
    "def extract_marker_matrix(adata, markers):\n",
    "    \"\"\"Extract marker gene expression matrix from AnnData\"\"\"\n",
    "    # Convert var_names to lowercase for case-insensitive matching\n",
    "    var_lower = {g.lower(): g for g in adata.var_names}\n",
    "    \n",
    "    # Find markers present in dataset (case-insensitive)\n",
    "    present = [var_lower[g.lower()] for g in markers if g.lower() in var_lower]\n",
    "    \n",
    "    if len(present) < 2:\n",
    "        raise ValueError(f\"Fewer than 2 marker genes present in dataset. Found: {present}\")\n",
    "    \n",
    "    # Extract expression matrix as DataFrame\n",
    "    X_df = pd.DataFrame(\n",
    "        adata[:, present].X.A if sp.issparse(adata.X) else adata[:, present].X,\n",
    "        index=adata.obs_names,\n",
    "        columns=present,\n",
    "    )\n",
    "    \n",
    "    # Drop constant columns that don't provide information\n",
    "    nonconst = (X_df != X_df.iloc[0]).any()\n",
    "    if (~nonconst).any():\n",
    "        dropped = X_df.columns[~nonconst].tolist()\n",
    "        warnings.warn(f\"Dropping constant marker(s): {dropped}\")\n",
    "        X_df = X_df.loc[:, nonconst]\n",
    "        present = X_df.columns.tolist()\n",
    "    \n",
    "    if len(present) < 2:\n",
    "        raise ValueError(\"Need â‰¥2 informative markers after filtering.\")\n",
    "    \n",
    "    print(f\"Markers used ({len(present)}): {present}\")\n",
    "    \n",
    "    return X_df, present\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â• 1) Load datasets â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"Loading MLL dataset (training data)...\")\n",
    "mll_adata = sc.read_h5ad(MLL_H5AD)\n",
    "mll_adata = unify_gene_symbols(mll_adata)\n",
    "mll_adata, mll_y = extract_sex_labels(mll_adata)\n",
    "print(f\"MLL dataset: {mll_adata.n_obs:,} cells  \"\n",
    "      f\"(â™€ {(mll_y==0).sum()}  â™‚ {(mll_y==1).sum()})\")\n",
    "\n",
    "print(\"\\nLoading ATL dataset (test data)...\")  # Changed to ATL as test data\n",
    "test_adata = sc.read_h5ad(ATL_H5AD)\n",
    "test_adata = unify_gene_symbols(test_adata)\n",
    "test_adata, y_test = extract_sex_labels(test_adata)\n",
    "print(f\"ATL dataset: {test_adata.n_obs:,} cells  \"  # Changed to ATL\n",
    "      f\"(â™€ {(y_test==0).sum()}  â™‚ {(y_test==1).sum()})\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â• 2) Subsample MLL dataset (1/15) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\nExtracting 1/15 random subsample from MLL dataset...\")\n",
    "subsample_size = len(mll_adata) // 15\n",
    "\n",
    "indices = np.arange(len(mll_adata))\n",
    "_, subsample_indices, _, y_subsample = train_test_split(\n",
    "    indices, mll_y, test_size=subsample_size/len(mll_adata), \n",
    "    stratify=mll_y, random_state=42\n",
    ")\n",
    "\n",
    "# Create subsampled AnnData object for training\n",
    "train_adata = mll_adata[subsample_indices].copy()\n",
    "y_train = mll_y[subsample_indices]\n",
    "print(f\"Training subsample: {train_adata.n_obs:,} cells  \"\n",
    "      f\"(â™€ {(y_train==0).sum()}  â™‚ {(y_train==1).sum()})\")\n",
    "print(f\"Subsampling ratio: {train_adata.n_obs/mll_adata.n_obs:.1%} of original MLL data\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â• 3) Extract marker matrices â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\nExtracting selected marker genes from training data...\")\n",
    "X_train_df, train_markers = extract_marker_matrix(train_adata, SELECTED_MARKERS)\n",
    "\n",
    "print(\"\\nExtracting selected marker genes from test data...\")\n",
    "X_test_df, test_markers = extract_marker_matrix(test_adata, SELECTED_MARKERS)\n",
    "\n",
    "# Find common markers between train and test sets\n",
    "common_markers = sorted(set(train_markers) & set(test_markers))\n",
    "if len(common_markers) < 2:\n",
    "    raise ValueError(f\"Fewer than 2 common marker genes between datasets. Found: {common_markers}\")\n",
    "\n",
    "print(f\"\\nCommon markers used for training and testing ({len(common_markers)}): {common_markers}\")\n",
    "\n",
    "# Use only common markers\n",
    "X_train = X_train_df[common_markers].values\n",
    "X_test = X_test_df[common_markers].values\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â• 4) Define models â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "pipelines = {\n",
    "    \"LogisticRegression\": make_pipe(LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    \"LinearSVC\": make_pipe(SVC(kernel=\"linear\", probability=True, random_state=42)),\n",
    "    \"XGBoost\": make_pipe(XGBClassifier(\n",
    "        eval_metric=\"logloss\", random_state=42,\n",
    "        n_estimators=100, learning_rate=0.05, max_depth=10)),\n",
    "    \"RandomForest\": make_pipe(RandomForestClassifier(max_depth=10, random_state=42)),\n",
    "}\n",
    "\n",
    "# Set up for curve data collection and plotting\n",
    "curve_data_roc = []\n",
    "curve_data_pr = []\n",
    "colors = {\n",
    "    \"LogisticRegression\": \"blue\",\n",
    "    \"LinearSVC\": \"red\",\n",
    "    \"XGBoost\": \"green\",\n",
    "    \"RandomForest\": \"purple\"\n",
    "}\n",
    "\n",
    "# Create figures for plotting\n",
    "fig_roc, ax_roc = plt.subplots(figsize=(10, 8))\n",
    "fig_pr, ax_pr = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â• 5) Train and evaluate models â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training and evaluating models using selected genes\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results = []\n",
    "for name, model in pipelines.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 1) Train performance\n",
    "    p_tr = model.predict(X_train)\n",
    "    prob_tr = model.predict_proba(X_train)[:, 1]\n",
    "    tr_acc = accuracy_score(y_train, p_tr)\n",
    "    tr_f1 = f1_score(y_train, p_tr)\n",
    "    tr_roc = roc_auc_score(y_train, prob_tr)\n",
    "    tr_pr = average_precision_score(y_train, prob_tr)\n",
    "    print(f\" TRAIN â†’ Acc={tr_acc:.4f}, F1={tr_f1:.4f}, AUROC={tr_roc:.4f}, AUPRC={tr_pr:.4f}\")\n",
    "\n",
    "    # 2) Test performance\n",
    "    p_test = model.predict(X_test)\n",
    "    prob_test = model.predict_proba(X_test)[:, 1]\n",
    "    test_acc = accuracy_score(y_test, p_test)\n",
    "    test_f1 = f1_score(y_test, p_test)\n",
    "    test_roc = roc_auc_score(y_test, prob_test)\n",
    "    test_pr = average_precision_score(y_test, prob_test)\n",
    "    print(f\" TEST â†’ Acc={test_acc:.4f}, F1={test_f1:.4f}, AUROC={test_roc:.4f}, AUPRC={test_pr:.4f}\")\n",
    "    print(\"  Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, p_test))\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train_Acc\": tr_acc, \"Train_F1\": tr_f1,\n",
    "        \"Train_AUROC\": tr_roc, \"Train_AUPRC\": tr_pr,\n",
    "        \"Test_Acc\": test_acc, \"Test_F1\": test_f1,\n",
    "        \"Test_AUROC\": test_roc, \"Test_AUPRC\": test_pr,\n",
    "    })\n",
    "    \n",
    "    # Calculate ROC curve points\n",
    "    fpr, tpr, _ = roc_curve(y_test, prob_test)\n",
    "    roc_df = pd.DataFrame({\"model\": name, \"fpr\": fpr, \"tpr\": tpr})\n",
    "    curve_data_roc.append(roc_df)\n",
    "    \n",
    "    # Calculate PR curve points\n",
    "    precision, recall, _ = precision_recall_curve(y_test, prob_test)\n",
    "    pr_df = pd.DataFrame({\"model\": name, \"precision\": precision, \"recall\": recall})\n",
    "    curve_data_pr.append(pr_df)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    ax_roc.plot(fpr, tpr, lw=2, color=colors[name], \n",
    "             label=f'{name} (area = {test_roc:.3f})')\n",
    "    \n",
    "    # Plot PR curve\n",
    "    ax_pr.plot(recall, precision, lw=2, color=colors[name], \n",
    "            label=f'{name} (area = {test_pr:.3f})')\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â• 6) Save results â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Combine and save curve data\n",
    "all_roc_data = pd.concat(curve_data_roc, ignore_index=True)\n",
    "all_pr_data = pd.concat(curve_data_pr, ignore_index=True)\n",
    "\n",
    "all_roc_data.to_csv(OUT_DIR / \"human2_to_human1_selected_auroc.csv\", index=False)\n",
    "all_pr_data.to_csv(OUT_DIR / \"human2_to_human1_selected_auprc.csv\", index=False)\n",
    "\n",
    "# Finalize and save ROC plot\n",
    "ax_roc.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "ax_roc.set_xlim([0.0, 1.0])\n",
    "ax_roc.set_ylim([0.0, 1.05])\n",
    "ax_roc.set_xlabel('False Positive Rate')\n",
    "ax_roc.set_ylabel('True Positive Rate')\n",
    "ax_roc.set_title('Human2 (MLL) â†’ Human1 (ATL): ROC Curves (Selected Genes)')\n",
    "ax_roc.legend(loc=\"lower right\")\n",
    "ax_roc.grid(True, linestyle='--', alpha=0.7)\n",
    "fig_roc.tight_layout()\n",
    "fig_roc.savefig(OUT_DIR / \"human2_to_human1_selected_roc_curves.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Finalize and save PR plot\n",
    "ax_pr.set_xlabel('Recall')\n",
    "ax_pr.set_ylabel('Precision')\n",
    "ax_pr.set_ylim([0.0, 1.05])\n",
    "ax_pr.set_xlim([0.0, 1.0])\n",
    "ax_pr.set_title('Human2 (MLL) â†’ Human1 (ATL): Precision-Recall Curves (Selected Genes)')\n",
    "ax_pr.legend(loc=\"lower left\")\n",
    "ax_pr.grid(True, linestyle='--', alpha=0.7)\n",
    "fig_pr.tight_layout()\n",
    "fig_pr.savefig(OUT_DIR / \"human2_to_human1_selected_pr_curves.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "# Save summary results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nFinal results:\")\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv(OUT_DIR / \"human2_to_human1_selected_summary_results.csv\", index=False)\n",
    "print(f\"\\nAll results saved to {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be2108",
   "metadata": {},
   "source": [
    "## Kidney Dataset: Donor Cell Analysis (GSE151671)\n",
    "\n",
    "## Overview\n",
    "Analysis of donor kidney cells for unbiased expression-sex analysis. This dataset serves as an important validation set for testing model generalizability across tissue types, as kidney samples represent healthy donor tissue without disease-related expression changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ed884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Loading HK\n",
      "â€¢ Loading AK1\n",
      "â€¢ Loading AK2\n",
      "â€¢ Concatenated: 18,000 cells Ã— 21,203 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haley/Library/Python/3.9/lib/python/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Filtered to kidney cells: 18,000 â†’ 1,404 cells\n",
      "â€¢ Donor sex distribution:\n",
      "donor_sex\n",
      "female    1200\n",
      "male       204\n",
      "Name: count, dtype: int64\n",
      "â€¢ Sample distribution:\n",
      "sample\n",
      "HK     1019\n",
      "AK1     204\n",
      "AK2     181\n",
      "Name: count, dtype: int64\n",
      "â€¢ Cell types kept:\n",
      "Cell_type\n",
      "vSMC2    265\n",
      "CD       235\n",
      "vSMC1    225\n",
      "PC1      185\n",
      "DVR      144\n",
      "IC-A     129\n",
      "PC2      124\n",
      "vSMC3     57\n",
      "vSMC4     40\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "âœ… KIDNEY_UNBIAS COMPLETED\n",
      "==================================================\n",
      "Final dataset: 1,404 cells Ã— 14,886 genes\n",
      "Saved to: GSE151671_RAW/kidney_unbias.h5ad\n",
      "\n",
      "DONOR SEX DISTRIBUTION:\n",
      "donor_sex\n",
      "female    1200\n",
      "male       204\n",
      "Name: count, dtype: int64\n",
      "\n",
      "SAMPLE DISTRIBUTION:\n",
      "sample\n",
      "HK     1019\n",
      "AK1     204\n",
      "AK2     181\n",
      "Name: count, dtype: int64\n",
      "\n",
      "TOP CELL TYPES (kidney only):\n",
      "Cell_type\n",
      "vSMC2    265\n",
      "CD       235\n",
      "vSMC1    225\n",
      "PC1      185\n",
      "DVR      144\n",
      "IC-A     129\n",
      "PC2      124\n",
      "vSMC3     57\n",
      "vSMC4     40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ğŸ¯ FOCUS: Only donor kidney cells included\n",
      "   â€¢ HK cells: female donor (healthy)\n",
      "   â€¢ AK1 cells: male donor (transplanted)\n",
      "   â€¢ AK2 cells: female donor (transplanted)\n",
      "   â€¢ Excluded: All recipient immune/circulating cells\n",
      "   â€¢ Ready for unbiased sex-expression analysis!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Kidney scRNA-seq merge + QC (UNBIASED VERSION)  â€¢  GSE151671\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "FOCUS: Only donor kidney cells for unbiased expression-sex analysis\n",
    "â€¢ Load three DGE tables (HK, AK1, AK2)  \n",
    "â€¢ Filter to keep ONLY parenchymal/kidney-resident cells (donor cells)\n",
    "â€¢ Assign sex based on DONOR sex (not recipient)\n",
    "â€¢ Remove recipient immune cells that confound sex-expression analysis\n",
    "â€¢ Save clean donor kidney dataset\n",
    "\"\"\"\n",
    "\n",
    "import os, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ USER PATHS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DATA_DIR = \"data/GSE151671_RAW\"\n",
    "data_files = {\n",
    "    \"HK\":  \"GSM4587971_HK.dge.txt.gz\",    # female healthy kidney\n",
    "    \"AK1\": \"GSM4587972_AK1.dge.txt.gz\",   # female recipient, MALE DONOR\n",
    "    \"AK2\": \"GSM4587973_AK2.dge.txt.gz\",   # male recipient, FEMALE DONOR\n",
    "}\n",
    "METADATA_PATH = \"data/GSE151671_Cell_barcode_assignment.xlsx\"\n",
    "OUTFILE       = os.path.join(DATA_DIR, \"kidney_unbias.h5ad\")\n",
    "\n",
    "VERBOSE = True\n",
    "TRACE_ASSIGN_SEX = False\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ KIDNEY CELL TYPES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Only parenchymal/resident kidney cells (DONOR cells)\n",
    "_kidney_parenchymal = {\n",
    "    \"PT\", \"PT1\", \"PT2\", \"PG\", \"LH\", \"CD\", \"IC-A\", \"IC-B\", \n",
    "    \"PTC1\", \"PTC2\", \"PTC3\", \"DVR\", \"FB1\", \"FB2\", \"FB3\", \"FB4\",\n",
    "    \"EC\", \"PC1\", \"PC2\", \"VSMC1\", \"VSMC2\", \"VSMC3\", \"VSMC4\",\n",
    "}\n",
    "\n",
    "# Immune/circulating cells to EXCLUDE (these are recipient cells)\n",
    "_immune_circulating = {\n",
    "    \"B\", \"T\", \"NK\", \"Macro\", \"DC\", \"Neutrophil\", \"Monocyte\", \n",
    "    \"Lymphocyte\", \"Plasma\", \"Mast\"\n",
    "}\n",
    "\n",
    "def is_kidney_cell(cell_type: str) -> bool:\n",
    "    \"\"\"Check if cell type is kidney parenchymal (donor) cell.\"\"\"\n",
    "    if pd.isna(cell_type):\n",
    "        return False\n",
    "    c = str(cell_type).upper().strip()\n",
    "    \n",
    "    # Direct match or substring match for parenchymal\n",
    "    is_parenchymal = any(t == c or t in c or c.startswith(t) for t in _kidney_parenchymal)\n",
    "    \n",
    "    # Exclude if clearly immune/circulating\n",
    "    is_immune = any(t in c or c.startswith(t) for t in _immune_circulating)\n",
    "    \n",
    "    return is_parenchymal and not is_immune\n",
    "\n",
    "def assign_donor_sex(sample: str, cell_type: str) -> str:\n",
    "    \"\"\"Return donor sex for kidney cells only.\"\"\"\n",
    "    if not is_kidney_cell(cell_type):\n",
    "        return \"exclude\"  # Mark for removal\n",
    "    \n",
    "    if TRACE_ASSIGN_SEX:\n",
    "        print(f\"assign_donor_sex({sample}, {cell_type}) -> kidney cell\")\n",
    "    \n",
    "    # Sex assignment based on DONOR\n",
    "    s = sample.upper()\n",
    "    if s == \"HK\":  return \"female\"  # healthy female kidney\n",
    "    if s == \"AK1\": return \"male\"    # male donor kidney  \n",
    "    if s == \"AK2\": return \"female\"  # female donor kidney\n",
    "    return \"unknown\"\n",
    "\n",
    "def read_dge(sample: str, path: str) -> sc.AnnData:\n",
    "    \"\"\"Load one DGE file â†’ AnnData with prefixed barcodes.\"\"\"\n",
    "    if VERBOSE: print(f\"â€¢ Loading {sample}\")\n",
    "    df = pd.read_csv(path, sep=\"\\t\", index_col=0)\n",
    "    if df.shape[0] > df.shape[1]:\n",
    "        df = df.T\n",
    "    if df.isna().values.any():\n",
    "        df = df.fillna(0)\n",
    "    barcodes = [f\"{sample}_{bc}\" for bc in df.index]\n",
    "    adata = sc.AnnData(\n",
    "        X   = sp.csr_matrix(df.values),\n",
    "        obs = pd.DataFrame(index=barcodes),\n",
    "        var = pd.DataFrame(index=df.columns),\n",
    "    )\n",
    "    adata.obs[\"sample\"] = sample\n",
    "    return adata\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) LOAD ALL SAMPLES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "adatas = [\n",
    "    read_dge(s, os.path.join(DATA_DIR, f))\n",
    "    for s, f in data_files.items()\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) CONCATENATE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "adata = sc.concat(\n",
    "    adatas,\n",
    "    join       = \"outer\",\n",
    "    merge      = \"first\", \n",
    "    fill_value = 0,\n",
    ")\n",
    "\n",
    "if not sp.issparse(adata.X):\n",
    "    adata.X = sp.csr_matrix(adata.X)\n",
    "if VERBOSE:\n",
    "    print(f\"â€¢ Concatenated: {adata.n_obs:,} cells Ã— {adata.n_vars:,} genes\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) MERGE METADATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "meta = (\n",
    "    pd.read_excel(METADATA_PATH, engine=\"openpyxl\")\n",
    "      .rename(columns=lambda x: x.strip())\n",
    "      .assign(Cell_barcode=lambda d: d[\"Cell_barcode\"].astype(str).str.strip().str.upper())\n",
    "      .set_index(\"Cell_barcode\")\n",
    ")\n",
    "adata.obs = adata.obs.merge(meta, left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) FILTER TO KIDNEY CELLS ONLY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if \"Cell_type\" not in adata.obs.columns:\n",
    "    warnings.warn(\"Metadata lacks 'Cell_type'; cannot filter kidney cells.\")\n",
    "    adata.obs[\"Cell_type\"] = \"unknown\"\n",
    "\n",
    "# Assign donor sex and filter\n",
    "adata.obs[\"donor_sex\"] = adata.obs.apply(\n",
    "    lambda r: assign_donor_sex(r[\"sample\"], r[\"Cell_type\"]), axis=1\n",
    ")\n",
    "\n",
    "# Keep only kidney cells (exclude immune/circulating cells)\n",
    "before_filter = adata.n_obs\n",
    "kidney_mask = adata.obs[\"donor_sex\"] != \"exclude\"\n",
    "adata = adata[kidney_mask, :].copy()\n",
    "\n",
    "if VERBOSE:\n",
    "    print(f\"â€¢ Filtered to kidney cells: {before_filter:,} â†’ {adata.n_obs:,} cells\")\n",
    "    print(\"â€¢ Donor sex distribution:\")\n",
    "    print(adata.obs[\"donor_sex\"].value_counts(dropna=False))\n",
    "    print(\"â€¢ Sample distribution:\")  \n",
    "    print(adata.obs[\"sample\"].value_counts())\n",
    "    print(\"â€¢ Cell types kept:\")\n",
    "    print(adata.obs[\"Cell_type\"].value_counts().head(10))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5) BASIC QC & NORMALISATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Filter genes (min 3 cells)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "# Filter cells (min 200 genes)\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "\n",
    "# Mitochondrial QC\n",
    "adata.var[\"mt\"] = adata.var_names.str.startswith((\"MT-\", \"mt-\"))\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\"], inplace=True)\n",
    "\n",
    " \n",
    "\n",
    "# Normalize and log-transform\n",
    "sc.pp.normalize_total(adata, target_sum=1e4, inplace=True)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "# Add additional metadata\n",
    "adata.obs[\"dataset\"] = \"kidney_unbias\"\n",
    "adata.obs[\"filtered_for\"] = \"donor_kidney_cells_only\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6) SAVE RESULTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "adata.write(OUTFILE, compression=\"gzip\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SUMMARY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âœ… KIDNEY_UNBIAS COMPLETED\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Final dataset: {adata.n_obs:,} cells Ã— {adata.n_vars:,} genes\")\n",
    "print(f\"Saved to: {OUTFILE}\")\n",
    "print(\"\\nDONOR SEX DISTRIBUTION:\")\n",
    "print(adata.obs[\"donor_sex\"].value_counts(dropna=False))\n",
    "print(\"\\nSAMPLE DISTRIBUTION:\")\n",
    "print(adata.obs[\"sample\"].value_counts())\n",
    "print(\"\\nTOP CELL TYPES (kidney only):\")\n",
    "print(adata.obs[\"Cell_type\"].value_counts().head(10))\n",
    "\n",
    "print(f\"\\nğŸ¯ FOCUS: Only donor kidney cells included\")\n",
    "print(f\"   â€¢ HK cells: female donor (healthy)\")  \n",
    "print(f\"   â€¢ AK1 cells: male donor (transplanted)\")\n",
    "print(f\"   â€¢ AK2 cells: female donor (transplanted)\")\n",
    "print(f\"   â€¢ Excluded: All recipient immune/circulating cells\")\n",
    "print(f\"   â€¢ Ready for unbiased sex-expression analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2091846",
   "metadata": {},
   "source": [
    "## Dataset 2: AML/MLL Bone Marrow Cells - GSE289435 (PRIMARY DATASET)\n",
    "\n",
    "### Background\n",
    "This dataset contains bone marrow mononuclear cells from patients with acute myeloid leukemia (AML) carrying mixed lineage leukemia (MLL) rearrangements. **This serves as our primary dataset for sex marker discovery and model training** due to its large sample size, balanced sex distribution, and comprehensive cell type diversity.\n",
    "\n",
    "### Dataset Characteristics\n",
    "- **Source**: GSE289435 (10X Genomics)\n",
    "- **Samples**: 13 patient samples (MLL_14666 to MLL_30886)\n",
    "- **Sex Distribution**: 6 female, 7 male patients (well-balanced)\n",
    "- **Cell Type**: Bone marrow mononuclear cells\n",
    "- **Primary Role**: **Training data and marker gene discovery**\n",
    "- **Secondary Role**: Self-validation through train/test splits\n",
    "\n",
    "### Significance as Primary Dataset\n",
    "This dataset is chosen as the foundation for analysis because:\n",
    "- **Large sample size**: 13 patients provide statistical power\n",
    "- **Balanced sex distribution**: Enables robust model training\n",
    "- **Cell type diversity**: Bone marrow contains multiple hematopoietic lineages\n",
    "- **High data quality**: 10X Genomics v3 chemistry\n",
    "- **Clinical relevance**: AML represents a well-characterized malignancy\n",
    "\n",
    "### Analysis Applications\n",
    "1. **Feature importance analysis**: Identify most informative sex-specific genes\n",
    "2. **Model training**: Develop and optimize ML algorithms\n",
    "3. **Internal validation**: 80/20 train/test splits for initial validation\n",
    "4. **Cross-dataset training**: Train models for testing on other tissue types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41048bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Loading MLL_14666\n",
      "â€¢ Successfully loaded MLL_14666: 12060 cells Ã— 36601 genes\n",
      "â€¢ Loading MLL_16703\n",
      "â€¢ Successfully loaded MLL_16703: 14986 cells Ã— 36601 genes\n",
      "â€¢ Loading MLL_17746\n",
      "â€¢ Successfully loaded MLL_17746: 9848 cells Ã— 36601 genes\n",
      "â€¢ Loading MLL_17843\n",
      "â€¢ Successfully loaded MLL_17843: 19508 cells Ã— 36601 genes\n",
      "â€¢ Loading MLL_17844\n",
      "â€¢ Successfully loaded MLL_17844: 25922 cells Ã— 36601 genes\n",
      "â€¢ Loading MLL_28824\n",
      "â€¢ Successfully loaded MLL_28824: 8719 cells Ã— 36601 genes\n",
      "â€¢ Loading MLL_28830\n",
      "â€¢ Successfully loaded MLL_28830: 10017 cells Ã— 36601 genes\n",
      "â€¢ Loading MLL_28855\n",
      "â€¢ Successfully loaded MLL_28855: 8059 cells Ã— 36601 genes\n",
      "â€¢ Loading MLL_29512_PDX\n",
      "â€¢ Successfully loaded MLL_29512_PDX: 9360 cells Ã— 36601 genes\n",
      "â€¢ Loading MLL_29532\n",
      "â€¢ Successfully loaded MLL_29532: 8475 cells Ã— 36601 genes\n",
      "â€¢ Loading MLL_29538\n",
      "â€¢ Successfully loaded MLL_29538: 6342 cells Ã— 36601 genes\n",
      "â€¢ Loading MLL_30862\n",
      "â€¢ Successfully loaded MLL_30862: 4600 cells Ã— 36601 genes\n",
      "â€¢ Loading MLL_30886\n",
      "â€¢ Successfully loaded MLL_30886: 15745 cells Ã— 36601 genes\n",
      "â€¢ Concatenating datasets\n",
      "â€¢ Concatenated: 153,641 cells Ã— 36,601 genes\n",
      "â€¢ Performing QC and filtering\n",
      "â€¢ Normalizing data\n",
      "â€¢ Writing to /Users/haley/Desktop/send_tooo/human_2/mll_merged_qc.h5ad\n",
      "âœ… Finished:\n",
      "   Cells  : 87,171\n",
      "   Genes  : 27,604\n",
      "   Sex    :\n",
      "sex\n",
      "female    44716\n",
      "male      42455\n",
      "Name: count, dtype: int64\n",
      "   Samples:\n",
      "sample\n",
      "MLL_17843        16163\n",
      "MLL_30886        14085\n",
      "MLL_14666        10183\n",
      "MLL_16703         9675\n",
      "MLL_17844         6521\n",
      "MLL_28855         6356\n",
      "MLL_29512_PDX     5875\n",
      "MLL_17746         4645\n",
      "MLL_28824         4242\n",
      "MLL_29532         3753\n",
      "MLL_29538         2339\n",
      "MLL_28830         1751\n",
      "MLL_30862         1583\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "MLL scRNA-seq merge + QC â€¢ GSE289435\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "- Load 10X Genomics datasets for MLL patient samples\n",
    "- Prefix barcodes with sample name\n",
    "- Concatenate matrices\n",
    "- Assign sex labels based on provided information\n",
    "- Perform QC filtering (min_genes, mitochondrial content)\n",
    "- Library-size normalize, log1p transform\n",
    "- Save sparse .h5ad\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio\n",
    "import sys\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ USER PATHS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DATA_DIR = \"/Users/haley/Desktop/send_tooo/GSE289435_RAW\"\n",
    "OUTDIR = \"/Users/haley/Desktop/send_tooo/human_2\"\n",
    "OUTFILE = os.path.join(OUTDIR, \"mll_merged_qc.h5ad\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# Sample information with sex labels\n",
    "sample_info = {\n",
    "    \"MLL_14666\": {\"gsm_id\": \"8791432\", \"sex\": \"female\"},\n",
    "    \"MLL_16703\": {\"gsm_id\": \"8791433\", \"sex\": \"female\"},\n",
    "    \"MLL_17746\": {\"gsm_id\": \"8791434\", \"sex\": \"male\"},\n",
    "    \"MLL_17843\": {\"gsm_id\": \"8791435\", \"sex\": \"female\"},\n",
    "    \"MLL_17844\": {\"gsm_id\": \"8791436\", \"sex\": \"male\"},\n",
    "    \"MLL_28824\": {\"gsm_id\": \"8791437\", \"sex\": \"male\"},\n",
    "    \"MLL_28830\": {\"gsm_id\": \"8791438\", \"sex\": \"male\"},\n",
    "    \"MLL_28855\": {\"gsm_id\": \"8791439\", \"sex\": \"female\"},\n",
    "    \"MLL_29512_PDX\": {\"gsm_id\": \"8791440\", \"sex\": \"male\"},\n",
    "    \"MLL_29532\": {\"gsm_id\": \"8791441\", \"sex\": \"male\"},\n",
    "    \"MLL_29538\": {\"gsm_id\": \"8791442\", \"sex\": \"female\"},\n",
    "    \"MLL_30862\": {\"gsm_id\": \"8791443\", \"sex\": \"male\"},\n",
    "    \"MLL_30886\": {\"gsm_id\": \"8791444\", \"sex\": \"male\"}\n",
    "}\n",
    "\n",
    "VERBOSE = True  # one-line progress prints\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def load_10x_data(sample_id: str, data_dir: str) -> sc.AnnData:\n",
    "    \"\"\"Load one 10X Genomics dataset using direct file loading.\"\"\"\n",
    "    if VERBOSE: print(f\"â€¢ Loading {sample_id}\")\n",
    "    \n",
    "    # Get GSM ID from the sample info\n",
    "    gsm_id = sample_info[sample_id][\"gsm_id\"]\n",
    "    \n",
    "    # File paths\n",
    "    matrix_file = os.path.join(data_dir, f\"GSM{gsm_id}_{sample_id}.matrix.mtx.gz\")\n",
    "    features_file = os.path.join(data_dir, f\"GSM{gsm_id}_{sample_id}.features.tsv.gz\")\n",
    "    barcodes_file = os.path.join(data_dir, f\"GSM{gsm_id}_{sample_id}.barcodes.tsv.gz\")\n",
    "    \n",
    "    # Check if files exist\n",
    "    for file_path in [matrix_file, features_file, barcodes_file]:\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            return None\n",
    "    \n",
    "    try:\n",
    "        # Load matrix\n",
    "        X = spio.mmread(matrix_file).T.tocsr()\n",
    "        \n",
    "        # Load features (genes)\n",
    "        features = pd.read_csv(features_file, sep='\\t', header=None)\n",
    "        if features.shape[1] >= 2:\n",
    "            # The second column typically contains gene symbols\n",
    "            gene_names = features[1].values\n",
    "        else:\n",
    "            # If there's only one column, use it as both ID and name\n",
    "            gene_names = features[0].values\n",
    "        \n",
    "        # Make gene names unique\n",
    "        gene_names_unique = make_unique_names(gene_names)\n",
    "        \n",
    "        # Load barcodes\n",
    "        barcodes = pd.read_csv(barcodes_file, sep='\\t', header=None)[0].values\n",
    "        \n",
    "        # Create AnnData object\n",
    "        adata = sc.AnnData(X=X)\n",
    "        adata.obs_names = [f\"{sample_id}_{bc}\" for bc in barcodes]\n",
    "        adata.var_names = gene_names_unique\n",
    "        \n",
    "        # Add sample and sex information\n",
    "        adata.obs[\"sample\"] = sample_id\n",
    "        adata.obs[\"sex\"] = sample_info[sample_id][\"sex\"]\n",
    "        \n",
    "        return adata\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {sample_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "def make_unique_names(names):\n",
    "    \"\"\"Make duplicate names unique by appending numbers.\"\"\"\n",
    "    name_counts = {}\n",
    "    unique_names = []\n",
    "    \n",
    "    for name in names:\n",
    "        if name in name_counts:\n",
    "            name_counts[name] += 1\n",
    "            unique_names.append(f\"{name}_{name_counts[name]}\")\n",
    "        else:\n",
    "            name_counts[name] = 0\n",
    "            unique_names.append(name)\n",
    "    \n",
    "    return unique_names\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) LOAD ALL SAMPLES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "adatas = []\n",
    "for sample_id in sample_info.keys():\n",
    "    adata = load_10x_data(sample_id, DATA_DIR)\n",
    "    if adata is not None:\n",
    "        adatas.append(adata)\n",
    "        if VERBOSE:\n",
    "            print(f\"â€¢ Successfully loaded {sample_id}: {adata.n_obs} cells Ã— {adata.n_vars} genes\")\n",
    "    else:\n",
    "        print(f\"âŒ Failed to load {sample_id}\")\n",
    "\n",
    "# Check if we have data to work with\n",
    "if not adatas:\n",
    "    print(\"No data was successfully loaded. Exiting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) CONCATENATE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if VERBOSE: print(\"â€¢ Concatenating datasets\")\n",
    "if len(adatas) == 1:\n",
    "    # If only one dataset was loaded, skip concatenation\n",
    "    adata = adatas[0].copy()\n",
    "    print(\"Only one dataset was loaded, skipping concatenation\")\n",
    "else:\n",
    "    # Concatenate multiple datasets\n",
    "    adata = sc.concat(\n",
    "        adatas,\n",
    "        join=\"outer\",     # Union of genes\n",
    "        merge=\"first\",\n",
    "        fill_value=0,     # Fill gaps with 0\n",
    "    )\n",
    "\n",
    "# Ensure the data is sparse\n",
    "if not sp.issparse(adata.X):\n",
    "    adata.X = sp.csr_matrix(adata.X)\n",
    "\n",
    "if VERBOSE:\n",
    "    print(f\"â€¢ Concatenated: {adata.n_obs:,} cells Ã— {adata.n_vars:,} genes\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) BASIC QC & FILTERING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if VERBOSE: print(\"â€¢ Performing QC and filtering\")\n",
    "\n",
    "# Filter genes with low expression\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "# Filter cells with few expressed genes\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "\n",
    "# Identify mitochondrial genes (human MT genes start with MT-)\n",
    "adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "\n",
    "# Calculate QC metrics\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\"], inplace=True)\n",
    "\n",
    "# Filter cells with high mitochondrial content\n",
    "max_mito_percent = 5\n",
    "adata = adata[adata.obs[\"pct_counts_mt\"] < max_mito_percent, :].copy()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) NORMALIZATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if VERBOSE: print(\"â€¢ Normalizing data\")\n",
    "sc.pp.normalize_total(adata, target_sum=1e4, inplace=True)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5) WRITE OUTPUT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if VERBOSE: print(f\"â€¢ Writing to {OUTFILE}\")\n",
    "adata.write(OUTFILE, compression=\"gzip\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SUMMARY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"âœ… Finished:\")\n",
    "print(f\"   Cells  : {adata.n_obs:,}\")\n",
    "print(f\"   Genes  : {adata.n_vars:,}\")\n",
    "print(\"   Sex    :\")\n",
    "print(adata.obs[\"sex\"].value_counts(dropna=False))\n",
    "print(\"   Samples:\")\n",
    "print(adata.obs[\"sample\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d04ec",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis: Sex Marker Discovery from Dataset 2\n",
    "\n",
    "### Objective\n",
    "**Primary Goal**: Systematically identify the most robust sex-specific markers using our comprehensive MLL/AML dataset (Dataset 2) as the discovery cohort.\n",
    "\n",
    "### Rationale for Using Dataset 2\n",
    "- **Statistical Power**: 13 patients provide sufficient samples for reliable importance estimates\n",
    "- **Biological Diversity**: Bone marrow contains multiple cell types, identifying universal markers\n",
    "- **Balanced Design**: Equal sex distribution prevents bias in marker selection\n",
    "- **Quality Data**: High-quality 10X data ensures accurate gene expression measurements\n",
    "\n",
    "### Methodology\n",
    "**Discovery Strategy**: \n",
    "- Extract 1/5 random subset for computational efficiency\n",
    "- Apply 4 complementary ML algorithms (Logistic, SVM, XGBoost, Random Forest)\n",
    "- Use 5-fold cross-validation for robust importance estimates\n",
    "- Identify consensus markers selected by â‰¥3 models\n",
    "\n",
    "### Expected Outcomes\n",
    "- **Ranked gene lists**: Most important sex markers for each algorithm\n",
    "- **Consensus markers**: Genes consistently selected across models\n",
    "- **Validation of known markers**: Confirm XIST, RPS4Y1, etc. are top-ranked\n",
    "- **Novel marker discovery**: Identify additional robust sex-specific genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c7dcb7",
   "metadata": {},
   "source": [
    "Here is an example of how to find human marekrs using 5 fold(one seed only here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199e101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STEP] Reading mll_merged_qc.h5ad â€¦\n",
      "â–¶ Dataset: 87,171 cells â”€ â™€ 44716  â™‚ 42455\n",
      "[STEP] Extracting 1/15 random subsample of data...\n",
      "â–¶ Subsample: 5,811 cells â”€ â™€ 2981  â™‚ 2830\n",
      "â–¶ Subsampling ratio: 6.7% of original data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/8s12n9193cs3klhgvl8yg4p80000gn/T/ipykernel_12756/4095119093.py:86: UserWarning: Dropping 4611 constant genes\n",
      "  warnings.warn(f\"Dropping {dropped} constant genes\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ Matrix: 5811 cells Ã— 22980 genes\n",
      "\n",
      "[CV] Fold 1/5\n",
      "   â–¶ Training: 4648 cells, Testing: 1163 cells\n",
      "   â€“ LogisticRegressionâ€¦ Acc=0.983 F1=0.982 AUROC=0.999 AUPRC=0.999\n",
      "   â€“ LinearSVCâ€¦ Acc=0.990 F1=0.989 AUROC=0.999 AUPRC=0.999\n",
      "   â€“ XGBoostâ€¦ Acc=0.982 F1=0.981 AUROC=0.998 AUPRC=0.999\n",
      "   â€“ RandomForestâ€¦ Acc=0.936 F1=0.934 AUROC=0.987 AUPRC=0.988\n",
      "\n",
      "[CV] Fold 2/5\n",
      "   â–¶ Training: 4649 cells, Testing: 1162 cells\n",
      "   â€“ LogisticRegressionâ€¦ Acc=0.985 F1=0.985 AUROC=0.997 AUPRC=0.998\n",
      "   â€“ LinearSVCâ€¦ Acc=0.982 F1=0.981 AUROC=0.997 AUPRC=0.997\n",
      "   â€“ XGBoostâ€¦ Acc=0.985 F1=0.985 AUROC=0.998 AUPRC=0.998\n",
      "   â€“ RandomForestâ€¦ Acc=0.933 F1=0.931 AUROC=0.986 AUPRC=0.985\n",
      "\n",
      "[CV] Fold 3/5\n",
      "   â–¶ Training: 4649 cells, Testing: 1162 cells\n",
      "   â€“ LogisticRegressionâ€¦ Acc=0.983 F1=0.982 AUROC=0.999 AUPRC=0.998\n",
      "   â€“ LinearSVCâ€¦ Acc=0.981 F1=0.981 AUROC=0.998 AUPRC=0.998\n",
      "   â€“ XGBoostâ€¦ Acc=0.985 F1=0.985 AUROC=0.999 AUPRC=0.999\n",
      "   â€“ RandomForestâ€¦ Acc=0.940 F1=0.937 AUROC=0.987 AUPRC=0.987\n",
      "\n",
      "[CV] Fold 4/5\n",
      "   â–¶ Training: 4649 cells, Testing: 1162 cells\n",
      "   â€“ LogisticRegressionâ€¦ Acc=0.977 F1=0.976 AUROC=0.997 AUPRC=0.996\n",
      "   â€“ LinearSVCâ€¦ Acc=0.975 F1=0.975 AUROC=0.996 AUPRC=0.996\n",
      "   â€“ XGBoostâ€¦ Acc=0.988 F1=0.988 AUROC=0.999 AUPRC=0.999\n",
      "   â€“ RandomForestâ€¦ Acc=0.936 F1=0.934 AUROC=0.985 AUPRC=0.986\n",
      "\n",
      "[CV] Fold 5/5\n",
      "   â–¶ Training: 4649 cells, Testing: 1162 cells\n",
      "   â€“ LogisticRegressionâ€¦ Acc=0.973 F1=0.972 AUROC=0.997 AUPRC=0.997\n",
      "   â€“ LinearSVCâ€¦ Acc=0.974 F1=0.973 AUROC=0.995 AUPRC=0.995\n",
      "   â€“ XGBoostâ€¦ Acc=0.982 F1=0.981 AUROC=0.997 AUPRC=0.998\n",
      "   â€“ RandomForestâ€¦ Acc=0.939 F1=0.936 AUROC=0.983 AUPRC=0.985\n",
      "\n",
      "[STEP] Aggregating feature importances â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yw/8s12n9193cs3klhgvl8yg4p80000gn/T/ipykernel_12756/4095119093.py:180: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=mean_imp.head(20), y=\"Feature\", x=\"Importance\", palette=\"viridis\")\n",
      "/var/folders/yw/8s12n9193cs3klhgvl8yg4p80000gn/T/ipykernel_12756/4095119093.py:180: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=mean_imp.head(20), y=\"Feature\", x=\"Importance\", palette=\"viridis\")\n",
      "/var/folders/yw/8s12n9193cs3klhgvl8yg4p80000gn/T/ipykernel_12756/4095119093.py:180: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=mean_imp.head(20), y=\"Feature\", x=\"Importance\", palette=\"viridis\")\n",
      "/var/folders/yw/8s12n9193cs3klhgvl8yg4p80000gn/T/ipykernel_12756/4095119093.py:180: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=mean_imp.head(20), y=\"Feature\", x=\"Importance\", palette=\"viridis\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP] Generating ROC and PR curves â€¦\n",
      "\n",
      "[STEP] Summarizing metrics â€¦\n",
      "\n",
      "Final 5-fold CV metrics:\n",
      "--------------------------------------------------\n",
      "             Model  Accuracy     F1  AUROC  AUPRC\n",
      "LogisticRegression    0.9802 0.9797 0.9977 0.9976\n",
      "         LinearSVC    0.9804 0.9798 0.9969 0.9970\n",
      "           XGBoost    0.9845 0.9839 0.9984 0.9985\n",
      "      RandomForest    0.9368 0.9345 0.9857 0.9859\n",
      "--------------------------------------------------\n",
      "\n",
      "Results saved to /Users/haley/Desktop/send_tooo/human_2/sex_marker_analysis_subsample\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Gene importance analysis for sex classification â€“ GSE289435 MLL dataset\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "- Loads the preâ€‘processed `mll_merged_qc.h5ad` produced by the merge/QC           \n",
    "  script (dataâ€‘2).                                                                  \n",
    "- Extracts a random 1/5 subsample of the entire dataset, then performs 5â€‘fold stratified CV\n",
    "  using four ML pipelines, each bundling `StandardScaler()` + model:                                                      \n",
    "    â€“ Logistic Regression                                                          \n",
    "    â€“ Linearâ€‘kernel SVC (probability = True)                                       \n",
    "    â€“ XGBoost                                                                       \n",
    "    â€“ Random Forest                                                                \n",
    "- Collects and aggregates feature importances, writes perâ€‘model CSV/plots,         \n",
    "  consensus gene list, ROC+PR curves, and final metrics.                           \n",
    "\n",
    "Edit the *PATHS* block if your directory structure changes.                         \n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    ")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• PATHS â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "DATA_DIR  = Path(\"/Users/haley/Desktop/send_tooo/human_2\").expanduser()\n",
    "H5AD_FILE = DATA_DIR / \"mll_merged_qc.h5ad\"\n",
    "OUT_DIR   = DATA_DIR / \"sex_marker_analysis_subsample\"\n",
    "FEATURE_DIR = OUT_DIR / \"feature_importance\"\n",
    "FEATURE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• HELPERS â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def make_pipe(model):\n",
    "    \"\"\"Return a sklearn Pipeline: StandardScaler â†’ model.\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\",    model),\n",
    "    ])\n",
    "\n",
    "\n",
    "def unify_gene_symbols(adata: sc.AnnData) -> sc.AnnData:\n",
    "    adata.var_names = adata.var_names.astype(str).str.upper()\n",
    "    if not adata.var_names.is_unique:\n",
    "        adata.var_names_make_unique()\n",
    "    return adata\n",
    "\n",
    "\n",
    "def extract_sex_labels(adata: sc.AnnData):\n",
    "    if \"sex\" not in adata.obs:\n",
    "        raise KeyError(\"'sex' column missing in AnnData.obs\")\n",
    "    y = (adata.obs[\"sex\"].astype(str).str.lower().str.strip() == \"male\").astype(int)\n",
    "    return adata.copy(), y.values\n",
    "\n",
    "\n",
    "def to_dataframe(adata: sc.AnnData) -> pd.DataFrame:\n",
    "    X = adata.X.A if sp.issparse(adata.X) else adata.X\n",
    "    df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names)\n",
    "    nonconst = (df != df.iloc[0]).any()\n",
    "    dropped = (~nonconst).sum()\n",
    "    if dropped:\n",
    "        warnings.warn(f\"Dropping {dropped} constant genes\")\n",
    "        df = df.loc[:, nonconst]\n",
    "    return df\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 1) LOAD DATA â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"[STEP] Reading mll_merged_qc.h5ad â€¦\")\n",
    "adata = sc.read_h5ad(H5AD_FILE)\n",
    "adata = unify_gene_symbols(adata)\n",
    "adata, y = extract_sex_labels(adata)\n",
    "print(f\"â–¶ Dataset: {adata.n_obs:,} cells â”€ â™€ {(y==0).sum()}  â™‚ {(y==1).sum()}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 2) EXTRACT 1/5 RANDOM SUBSAMPLE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Subsample 1/5 of the data while maintaining sex distribution\n",
    "print(\"[STEP] Extracting 1/15 random subsample of data...\")\n",
    "subsample_size = len(adata) // 15\n",
    "\n",
    "indices = np.arange(len(adata))\n",
    "_, subsample_indices, _, y_subsample = train_test_split(\n",
    "    indices, y, test_size=subsample_size/len(adata), \n",
    "    stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Create subsampled AnnData object\n",
    "adata_subsample = adata[subsample_indices].copy()\n",
    "y_subsample = y[subsample_indices]\n",
    "print(f\"â–¶ Subsample: {adata_subsample.n_obs:,} cells â”€ â™€ {(y_subsample==0).sum()}  â™‚ {(y_subsample==1).sum()}\")\n",
    "print(f\"â–¶ Subsampling ratio: {adata_subsample.n_obs/adata.n_obs:.1%} of original data\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 3) EXPRESSION MATRIX â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "X_df = to_dataframe(adata_subsample)\n",
    "print(f\"â–¶ Matrix: {X_df.shape[0]} cells Ã— {X_df.shape[1]} genes\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 4) PIPELINES â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "PIPES = {\n",
    "    \"LogisticRegression\": make_pipe(LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    \"LinearSVC\":          make_pipe(SVC(kernel=\"linear\", probability=True, random_state=42)),\n",
    "    \"XGBoost\":            make_pipe(XGBClassifier(\n",
    "        eval_metric=\"logloss\", random_state=42,\n",
    "        n_estimators=100, learning_rate=0.05, max_depth=10)),\n",
    "    \"RandomForest\":       make_pipe(RandomForestClassifier(max_depth=10, random_state=42)),\n",
    "}\n",
    "\n",
    "feat_imps = {name: [] for name in PIPES}\n",
    "preds    = {name: {\"y_true\": [], \"y_prob\": []} for name in PIPES}\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 5) 5â€‘FOLD CV ON SUBSAMPLE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (tr, te) in enumerate(skf.split(X_df, y_subsample), 1):\n",
    "    print(f\"\\n[CV] Fold {fold}/5\")\n",
    "    X_tr, X_te = X_df.iloc[tr], X_df.iloc[te]\n",
    "    y_tr, y_te = y_subsample[tr], y_subsample[te]\n",
    "    \n",
    "    print(f\"   â–¶ Training: {len(X_tr)} cells, Testing: {len(X_te)} cells\")\n",
    "\n",
    "    for name, pipe in PIPES.items():\n",
    "        print(f\"   â€“ {name}â€¦\", end=\"\", flush=True)\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "\n",
    "        # underlying estimator\n",
    "        est = pipe.named_steps[\"clf\"]\n",
    "        if hasattr(est, \"coef_\"):\n",
    "            imp = np.abs(est.coef_[0])\n",
    "        elif hasattr(est, \"feature_importances_\"):\n",
    "            imp = est.feature_importances_\n",
    "        else:\n",
    "            imp = np.zeros(X_tr.shape[1])\n",
    "        feat_imps[name].append(pd.DataFrame({\"Feature\": X_tr.columns, \"Importance\": imp}))\n",
    "\n",
    "        y_prob = pipe.predict_proba(X_te)[:, 1]\n",
    "        preds[name][\"y_true\"].extend(y_te)\n",
    "        preds[name][\"y_prob\"].extend(y_prob)\n",
    "\n",
    "        y_pred = (y_prob >= 0.5).astype(int)\n",
    "        acc = accuracy_score(y_te, y_pred)\n",
    "        f1  = f1_score(y_te, y_pred)\n",
    "        auc = roc_auc_score(y_te, y_prob)\n",
    "        ap  = average_precision_score(y_te, y_prob)\n",
    "        print(f\" Acc={acc:.3f} F1={f1:.3f} AUROC={auc:.3f} AUPRC={ap:.3f}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 6) IMPORTANCE AGGREGATION â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n[STEP] Aggregating feature importances â€¦\")\n",
    "agg, top20 = {}, {}\n",
    "for name, dfs in feat_imps.items():\n",
    "    mean_imp = (pd.concat(dfs)\n",
    "                  .groupby(\"Feature\")[\"Importance\"].mean()\n",
    "                  .sort_values(ascending=False)\n",
    "                  .reset_index())\n",
    "    mean_imp[\"Rank\"] = mean_imp[\"Importance\"].rank(method=\"dense\", ascending=False).astype(int)\n",
    "    agg[name] = mean_imp\n",
    "    csv_path = FEATURE_DIR / f\"{name}_feature_importances.csv\"\n",
    "    mean_imp.to_csv(csv_path, index=False)\n",
    "\n",
    "    top20[name] = mean_imp.head(20)[\"Feature\"].tolist()\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    sns.barplot(data=mean_imp.head(20), y=\"Feature\", x=\"Importance\", palette=\"viridis\")\n",
    "    plt.title(f\"Topâ€‘20 genes â€“ {name} (MLL Dataset)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FEATURE_DIR / f\"{name}_top20.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# consensus list\n",
    "counts = {}\n",
    "for genes in top20.values():\n",
    "    for g in genes:\n",
    "        counts[g] = counts.get(g, 0) + 1\n",
    "consensus = (pd.Series(counts, name=\"Models_Count\")\n",
    "               .sort_values(ascending=False)\n",
    "               .reset_index().rename(columns={\"index\": \"Gene\"}))\n",
    "consensus.to_csv(FEATURE_DIR / \"consensus_top_genes.csv\", index=False)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 7) ROC & PR CURVES â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n[STEP] Generating ROC and PR curves â€¦\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ROC Curves\n",
    "for name, p in preds.items():\n",
    "    fpr, tpr, _ = roc_curve(p[\"y_true\"], p[\"y_prob\"])\n",
    "    auc = roc_auc_score(p[\"y_true\"], p[\"y_prob\"])\n",
    "    ax1.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.3f})\")\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], 'k--')\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC Curves')\n",
    "ax1.legend()\n",
    "\n",
    "# PR Curves\n",
    "for name, p in preds.items():\n",
    "    precision, recall, _ = precision_recall_curve(p[\"y_true\"], p[\"y_prob\"])\n",
    "    ap = average_precision_score(p[\"y_true\"], p[\"y_prob\"])\n",
    "    ax2.plot(recall, precision, label=f\"{name} (AP = {ap:.3f})\")\n",
    "\n",
    "# Calculate baseline for PR curve (proportion of positive class)\n",
    "baseline = sum(preds[list(preds.keys())[0]][\"y_true\"]) / len(preds[list(preds.keys())[0]][\"y_true\"])\n",
    "ax2.plot([0, 1], [baseline, baseline], 'k--', label=f'Baseline ({baseline:.3f})')\n",
    "\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Precision-Recall Curves')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"roc_pr_curves.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• 8) FINAL METRICS â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n[STEP] Summarizing metrics â€¦\")\n",
    "metrics = []\n",
    "for name, p in preds.items():\n",
    "    y_true = np.array(p[\"y_true\"])\n",
    "    y_prob = np.array(p[\"y_prob\"])\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    \n",
    "    metrics.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"F1\": f1_score(y_true, y_pred),\n",
    "        \"AUROC\": roc_auc_score(y_true, y_prob),\n",
    "        \"AUPRC\": average_precision_score(y_true, y_prob)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df.to_csv(OUT_DIR / \"model_metrics.csv\", index=False)\n",
    "\n",
    "# Print a nice summary table\n",
    "print(\"\\nFinal 5-fold CV metrics:\\n\" + \"-\" * 50)\n",
    "print(metrics_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "print(\"-\" * 50)\n",
    "print(f\"\\nResults saved to {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e5bc6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genes selected by â‰¥3 models: ['RPS4Y1', 'EIF1AY', 'XIST', 'DDX3Y', 'UTY', 'KDM5D', 'IFIT3', 'IFIT2', 'RPS4X', 'RPL29']\n",
      "Genes selected by â‰¥3 models: ['RPS4Y1', 'IFIT2', 'XIST', 'DDX3Y', 'EIF1AY', 'RPS4X', 'RPL29', 'IFIT3', 'UTY', 'KDM5D']\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "#  right after you build `counts` or `consensus`\n",
    "# ----------------------------------------\n",
    "\n",
    "# Option 1 â€“ work directly from the `counts` dict\n",
    "genes_over_two = [g for g, c in counts.items() if c > 2]\n",
    "print(\"Genes selected by â‰¥3 models:\", genes_over_two)\n",
    "\n",
    "# Option 2 â€“ use the consensus DataFrame you just wrote\n",
    "genes_over_two = (\n",
    "    consensus.loc[consensus[\"Models_Count\"] > 2, \"Gene\"]\n",
    "    .tolist()\n",
    ")\n",
    "print(\"Genes selected by â‰¥3 models:\", genes_over_two)\n",
    "\n",
    "# (optional) save to disk\n",
    "(pd.Series(genes_over_two, name=\"Gene\")\n",
    "   .to_csv(FEATURE_DIR / \"genes_selected_by_3plus_models.csv\",\n",
    "           index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62aa33",
   "metadata": {},
   "source": [
    "## Gene Selection Robustness Analysis Across Random Seeds\n",
    "\n",
    "![Gene Selection Across Seeds](/Users/haley/Downloads/CellSexID-main/gene_seed_heatmap.png)\n",
    "\n",
    "**Figure**: Cross-validation analysis of gene selection consistency across five random seeds (42, 123, 456, 789, 999) using 10% random subsampling of the full MLL/AML dataset (Dataset 2). This methodological approach addresses computational constraints of the large dataset while maintaining statistical rigor through random sampling and multiple seed validation.\n",
    "\n",
    "### Methodological Approach:\n",
    "- **Dataset Sampling**: 10% random subset of the complete dataset to manage computational complexity\n",
    "- **Cross-Validation**: Five different random seeds to assess selection robustness  \n",
    "- **Rationale**: Random subsampling at 10% provides a computationally feasible yet statistically sound approach for large-scale marker discovery\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "**Highly Robust Markers (4/4 model consistency):**\n",
    "- DDX3Y, EIF1AY, IFIT2, UTY, RPS4Y1 - demonstrate exceptional stability across all random seeds\n",
    "\n",
    "**Moderately Robust Markers (3-4/4 model consistency):**  \n",
    "- RPS4X, XIST, IFIT3, KDM5D - show strong but not perfect consistency\n",
    "\n",
    "**Seed-Sensitive Markers:**\n",
    "- OASL: Selected only with seeds 456 and 789\n",
    "- USP9Y: Selected exclusively with seed 42\n",
    "\n",
    "### Conclusion:\n",
    "This cross-validation analysis identified **9 highly consistent sex prediction markers** that demonstrate robust selection patterns independent of random seed variation. The methodological choice of 10% random subsampling represents a pragmatic yet scientifically sound approach to marker discovery in large-scale genomic datasets, successfully identifying stable biomarkers while managing computational resources effectively.\n",
    "\n",
    "These 9 robust markers form the foundation of our human sex prediction gene signature, validated through this rigorous cross-seed consistency analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64277ab1",
   "metadata": {},
   "source": [
    "## Dataset 3: Thymic Epithelial Cells - GSE262749\n",
    "\n",
    "### Background\n",
    "Medullary thymic epithelial cells represent a highly specialized cell type involved in T-cell selection. This dataset tests model performance on tissue-specific epithelial cells.\n",
    "\n",
    "### Dataset Characteristics\n",
    "- **Source**: GSE262749 (10X Genomics)\n",
    "- **Samples**: 5 donors (DonorA-E)\n",
    "- **Sex Distribution**: 3 female, 2 male donors\n",
    "- **Cell Type**: Medullary thymic epithelial cells\n",
    "- **Role**: Validation on specialized epithelial tissue \n",
    "\n",
    "### Analytical Challenge\n",
    "**Tissue Specificity**: Thymic epithelial cells have unique expression profiles\n",
    "**Expected Performance**: Tests whether bone marrow-derived markers generalize to epithelial contexts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c261c15",
   "metadata": {},
   "source": [
    "\tThymic mimetic cells in humans [scRNA-seq]ï¼› medullary thymic epithelial cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1965189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Loading DonorA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haley/Library/Python/3.9/lib/python/site-packages/anndata/_core/anndata.py:430: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Loading DonorB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haley/Library/Python/3.9/lib/python/site-packages/anndata/_core/anndata.py:430: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Loading DonorC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haley/Library/Python/3.9/lib/python/site-packages/anndata/_core/anndata.py:430: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Loading DonorD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haley/Library/Python/3.9/lib/python/site-packages/anndata/_core/anndata.py:430: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Loading DonorE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haley/Library/Python/3.9/lib/python/site-packages/anndata/_core/anndata.py:430: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n",
      "  warnings.warn(\n",
      "/var/folders/yw/8s12n9193cs3klhgvl8yg4p80000gn/T/ipykernel_93739/2199064827.py:100: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f\"   â†³ {ad.obs['sample'][0]}: {ad.n_obs:,} cells  Ã—  {ad.n_vars:,} genes\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â†³ DonorA: 5,885 cells  Ã—  36,616 genes\n",
      "   â†³ DonorB: 8,215 cells  Ã—  36,616 genes\n",
      "   â†³ DonorC: 6,126 cells  Ã—  36,616 genes\n",
      "   â†³ DonorD: 6,633 cells  Ã—  36,616 genes\n",
      "   â†³ DonorE: 9,361 cells  Ã—  36,616 genes\n",
      "â€¢ Concatenating samples\n",
      "   Total: 36,220 cells  Ã—  36,616 genes\n",
      "â€¢ QC filtering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Removed 13 mitochondrial genes; 32,399 genes remain.\n",
      "â€¢ Normalising & log-transforming\n",
      "â€¢ Saving â†’ /Users/haley/Desktop/send_tooo/human_3/donor_merged_qc.h5ad\n",
      "âœ… Finished\n",
      "   Cells  : 25,379\n",
      "   Genes  : 32,399\n",
      "   Sex    :\n",
      "sex\n",
      "female    13508\n",
      "male      11871\n",
      "Name: count, dtype: int64\n",
      "   Samples:\n",
      "sample\n",
      "DonorD    6240\n",
      "DonorB    5631\n",
      "DonorA    5190\n",
      "DonorE    4355\n",
      "DonorC    3963\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "scRNA-seq merge + QC â€¢ GSE262749\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ Load 10X Genomics matrices for five donor samples\n",
    "â€¢ Prefix barcodes with sample ID\n",
    "â€¢ Concatenate into a single AnnData\n",
    "â€¢ Add sex labels\n",
    "â€¢ QC:\n",
    "   â€“ remove low-quality genes/cells\n",
    "   â€“ compute % mitochondrial reads\n",
    "   â€“ discard cells with high mito %\n",
    "   â€“ **drop mitochondrial genes from the matrix**\n",
    "â€¢ Library-size normalise, log1p transform\n",
    "â€¢ Save compressed .h5ad\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ USER PATHS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DATA_DIR = \"/Users/haley/Desktop/send_tooo/GSE262749_RAW\"\n",
    "OUTDIR   = \"/Users/haley/Desktop/send_tooo/human_3\"\n",
    "OUTFILE  = os.path.join(OUTDIR, \"donor_merged_qc.h5ad\")\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SAMPLE METADATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "sample_info = {\n",
    "    \"DonorA\": {\"gsm_id\": \"8178134\", \"sex\": \"female\"},\n",
    "    \"DonorB\": {\"gsm_id\": \"8178135\", \"sex\": \"male\"},\n",
    "    \"DonorC\": {\"gsm_id\": \"8178136\", \"sex\": \"female\"},\n",
    "    \"DonorD\": {\"gsm_id\": \"8178137\", \"sex\": \"male\"},\n",
    "    \"DonorE\": {\"gsm_id\": \"8178138\", \"sex\": \"female\"},\n",
    "}\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_unique(names):\n",
    "    \"\"\"Ensure gene names are unique (Scanpy requires this).\"\"\"\n",
    "    counts, unique = {}, []\n",
    "    for n in names:\n",
    "        if n in counts:\n",
    "            counts[n] += 1\n",
    "            unique.append(f\"{n}_{counts[n]}\")\n",
    "        else:\n",
    "            counts[n] = 0\n",
    "            unique.append(n)\n",
    "    return unique\n",
    "\n",
    "\n",
    "def load_10x(sample_id: str) -> sc.AnnData | None:\n",
    "    \"\"\"Load a single 10X dataset (matrix.mtx + features + barcodes).\"\"\"\n",
    "    gsm = sample_info[sample_id][\"gsm_id\"]\n",
    "    mat_f = os.path.join(DATA_DIR, f\"GSM{gsm}_{sample_id}_matrix.mtx.gz\")\n",
    "    feat_f = os.path.join(DATA_DIR, f\"GSM{gsm}_{sample_id}_features.tsv.gz\")\n",
    "    bc_f  = os.path.join(DATA_DIR, f\"GSM{gsm}_{sample_id}_barcodes.tsv.gz\")\n",
    "\n",
    "    for fp in (mat_f, feat_f, bc_f):\n",
    "        if not os.path.exists(fp):\n",
    "            print(f\"âŒ File not found: {fp}\")\n",
    "            return None\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(f\"â€¢ Loading {sample_id}\")\n",
    "\n",
    "    try:\n",
    "        X = spio.mmread(mat_f).T.tocsr()\n",
    "\n",
    "        genes_df = pd.read_csv(feat_f, sep=\"\\t\", header=None)\n",
    "        gene_names = genes_df[1].values if genes_df.shape[1] >= 2 else genes_df[0].values\n",
    "        gene_names = make_unique(gene_names)\n",
    "\n",
    "        barcodes = pd.read_csv(bc_f, sep=\"\\t\", header=None)[0].values\n",
    "        ad = sc.AnnData(X, dtype=np.int32)\n",
    "        ad.obs_names = [f\"{sample_id}_{bc}\" for bc in barcodes]\n",
    "        ad.var_names = gene_names\n",
    "        ad.obs[\"sample\"] = sample_id\n",
    "        ad.obs[\"sex\"]    = sample_info[sample_id][\"sex\"]\n",
    "        return ad\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading {sample_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) LOAD ALL SAMPLES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "adatas = [d for s in sample_info for d in (load_10x(s),) if d is not None]\n",
    "\n",
    "if not adatas:\n",
    "    sys.exit(\"No data loaded â€” exiting.\")\n",
    "\n",
    "if VERBOSE:\n",
    "    for ad in adatas:\n",
    "        print(f\"   â†³ {ad.obs['sample'][0]}: {ad.n_obs:,} cells  Ã—  {ad.n_vars:,} genes\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) CONCATENATE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if VERBOSE:\n",
    "    print(\"â€¢ Concatenating samples\")\n",
    "\n",
    "adata = adatas[0] if len(adatas) == 1 else sc.concat(adatas, join=\"outer\", merge=\"first\", fill_value=0)\n",
    "\n",
    "if not sp.issparse(adata.X):\n",
    "    adata.X = sp.csr_matrix(adata.X)\n",
    "\n",
    "if VERBOSE:\n",
    "    print(f\"   Total: {adata.n_obs:,} cells  Ã—  {adata.n_vars:,} genes\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) QC FILTERING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if VERBOSE:\n",
    "    print(\"â€¢ QC filtering\")\n",
    "\n",
    "# a) gene / cell minimums\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "\n",
    "# b) percent mitochondrial\n",
    "adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\"], inplace=True)\n",
    "\n",
    "adata = adata[adata.obs[\"pct_counts_mt\"] < 5].copy()\n",
    "\n",
    "# c) REMOVE MITOCHONDRIAL GENES\n",
    "n_mt = int(adata.var[\"mt\"].sum())\n",
    "adata = adata[:, ~adata.var[\"mt\"]].copy()\n",
    "\n",
    "if VERBOSE:\n",
    "    print(f\"   Removed {n_mt} mitochondrial genes; {adata.n_vars:,} genes remain.\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) NORMALISATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if VERBOSE:\n",
    "    print(\"â€¢ Normalising & log-transforming\")\n",
    "\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5) SAVE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if VERBOSE:\n",
    "    print(f\"â€¢ Saving â†’ {OUTFILE}\")\n",
    "\n",
    "adata.write(OUTFILE, compression=\"gzip\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SUMMARY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"âœ… Finished\")\n",
    "print(f\"   Cells  : {adata.n_obs:,}\")\n",
    "print(f\"   Genes  : {adata.n_vars:,}\")\n",
    "print(\"   Sex    :\")\n",
    "print(adata.obs[\"sex\"].value_counts(dropna=False))\n",
    "print(\"   Samples:\")\n",
    "print(adata.obs[\"sample\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15846d85",
   "metadata": {},
   "source": [
    "## Cross-Dataset Validation: Dataset 2 (MLL/AML) â†’ Dataset 3 (Thymic)\n",
    "\n",
    "### Experimental Design\n",
    "This analysis tests the generalizability of sex prediction models trained on bone marrow cells (Dataset 2) when applied to thymic epithelial cells (Dataset 3). This represents one of the most challenging cross-dataset validations due to the biological distance between hematopoietic and epithelial cell types.\n",
    "\n",
    "### Biological Rationale\n",
    "**Training Context**: Bone marrow mononuclear cells (diverse hematopoietic lineages)  \n",
    "**Testing Context**: Medullary thymic epithelial cells (specialized epithelial tissue)  \n",
    "**Challenge**: Test whether sex markers discovered in blood/immune cells generalize to epithelial contexts\n",
    "\n",
    "### Methodological Approach\n",
    "**Selected Marker Panel**: 9 carefully curated sex-specific genes identified from prior feature importance analysis \n",
    "\n",
    "**Training Strategy**:\n",
    "- 4 ML algorithms: Logistic Regression, SVM, XGBoost, Random Forest\n",
    "\n",
    "**Evaluation Framework**:\n",
    "- Cross-dataset performance metrics (AUROC, AUPRC, accuracy)\n",
    "- ROC and Precision-Recall curve generation\n",
    "- Model comparison across algorithms\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6b2ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MLL dataset...\n",
      "Renaming 16 genes using alias dictionary\n",
      "MLL dataset: 87,171 cells  (â™€ 44716  â™‚ 42455)\n",
      "\n",
      "Loading Donor dataset (test data)...\n",
      "Renaming 16 genes using alias dictionary\n",
      "Donor dataset: 25,379 cells  (â™€ 13508  â™‚ 11871)\n",
      "\n",
      "Extracting 1/15 random subsample from MLL dataset...\n",
      "Training subsample: 5,811 cells  (â™€ 2981  â™‚ 2830)\n",
      "Subsampling ratio: 6.7% of original MLL data\n",
      "\n",
      "Extracting selected marker genes from training data...\n",
      "Markers used (9): ['RPS4Y1', 'EIF1AY', 'Xist', 'Ddx3y', 'Uty', 'Kdm5d', 'IFIT3', 'IFIT2', 'RPS4X']\n",
      "\n",
      "Extracting selected marker genes from test data...\n",
      "Markers used (9): ['RPS4Y1', 'EIF1AY', 'Xist', 'Ddx3y', 'Uty', 'Kdm5d', 'IFIT3', 'IFIT2', 'RPS4X']\n",
      "\n",
      "Common markers used for training and testing (9): ['Ddx3y', 'EIF1AY', 'IFIT2', 'IFIT3', 'Kdm5d', 'RPS4X', 'RPS4Y1', 'Uty', 'Xist']\n",
      "\n",
      "==================================================\n",
      "Training and evaluating models using selected genes\n",
      "==================================================\n",
      "\n",
      "=== LogisticRegression ===\n",
      " TRAIN â†’ Acc=0.8954, F1=0.8816, AUROC=0.9615, AUPRC=0.9641\n",
      " TEST â†’ Acc=0.9764, F1=0.9742, AUROC=0.9985, AUPRC=0.9983\n",
      "  Confusion Matrix:\n",
      "[[13444    64]\n",
      " [  536 11335]]\n",
      "\n",
      "=== LinearSVC ===\n",
      " TRAIN â†’ Acc=0.8945, F1=0.8805, AUROC=0.9615, AUPRC=0.9643\n",
      " TEST â†’ Acc=0.9763, F1=0.9741, AUROC=0.9982, AUPRC=0.9980\n",
      "  Confusion Matrix:\n",
      "[[13462    46]\n",
      " [  555 11316]]\n",
      "\n",
      "=== XGBoost ===\n",
      " TRAIN â†’ Acc=0.9191, F1=0.9182, AUROC=0.9838, AUPRC=0.9837\n",
      " TEST â†’ Acc=0.9565, F1=0.9539, AUROC=0.9966, AUPRC=0.9961\n",
      "  Confusion Matrix:\n",
      "[[12840   668]\n",
      " [  437 11434]]\n",
      "\n",
      "=== RandomForest ===\n",
      " TRAIN â†’ Acc=0.9210, F1=0.9200, AUROC=0.9843, AUPRC=0.9840\n",
      " TEST â†’ Acc=0.9561, F1=0.9536, AUROC=0.9966, AUPRC=0.9963\n",
      "  Confusion Matrix:\n",
      "[[12813   695]\n",
      " [  420 11451]]\n",
      "\n",
      "Final results:\n",
      "                Model  Train_Acc  Train_F1  Train_AUROC  Train_AUPRC  \\\n",
      "0  LogisticRegression   0.895371  0.881620     0.961491     0.964143   \n",
      "1           LinearSVC   0.894510  0.880530     0.961468     0.964270   \n",
      "2             XGBoost   0.919119  0.918175     0.983814     0.983713   \n",
      "3        RandomForest   0.921012  0.919993     0.984268     0.983955   \n",
      "\n",
      "   Test_Acc   Test_F1  Test_AUROC  Test_AUPRC  \n",
      "0  0.976358  0.974216    0.998460    0.998284  \n",
      "1  0.976319  0.974132    0.998190    0.997984  \n",
      "2  0.956460  0.953906    0.996563    0.996051  \n",
      "3  0.956066  0.953575    0.996632    0.996319  \n",
      "\n",
      "All results saved to /Users/haley/Downloads/CellSexID-main/result\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Sex classification using MLL data (human_2) subsample as training and Donor data (human_3) as testing\n",
    "Using 9 selected marker genes: RPS4Y1, EIF1AY, XIST, DDX3Y, UTY, KDM5D, IFIT3, IFIT2, RPS4X\n",
    "Models: LogisticRegression, Linear-SVC, XGBoost, Random-Forest\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€ imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os, pathlib, warnings\n",
    "import numpy as np, pandas as pd, scanpy as sc, scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute            import SimpleImputer\n",
    "from sklearn.preprocessing     import StandardScaler\n",
    "from sklearn.pipeline          import Pipeline\n",
    "from sklearn.linear_model      import LogisticRegression\n",
    "from sklearn.svm               import SVC\n",
    "from sklearn.ensemble          import RandomForestClassifier\n",
    "from sklearn.model_selection   import train_test_split\n",
    "from xgboost                   import XGBClassifier\n",
    "from sklearn.metrics           import (\n",
    "    accuracy_score, f1_score, roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ selected marker panel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SELECTED_MARKERS = [\n",
    "    \"RPS4Y1\", \n",
    "    \"EIF1AY\", \n",
    "    \"XIST\", \n",
    "    \"DDX3Y\", \n",
    "    \"UTY\", \n",
    "    \"KDM5D\", \n",
    "    \"IFIT3\", \n",
    "    \"IFIT2\", \n",
    "    \"RPS4X\"\n",
    "]\n",
    "\n",
    "# â”€â”€â”€ alias dictionary for gene name mapping â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "alias_to_official = {\n",
    "    \"XIST\":\"Xist\", \"RPS27RT\":\"Rps27rt\", \"DDX3Y\":\"Ddx3y\", \"RPL35\":\"Rpl35\",\n",
    "    \"EIF2S3Y\":\"Eif2s3y\", \"EIF2S3L\":\"Eif2s3y\", \"GM42418\":\"Gm42418\", \"UBA52\":\"Uba52\",\n",
    "    \"RPL36A-PS1\":\"Rpl36a-ps1\", \"KDM5D\":\"Kdm5d\", \"JARID1D\":\"Kdm5d\", \"WDR89\":\"Wdr89\",\n",
    "    \"UTY\":\"Uty\", \"LARS2\":\"Lars2\", \"AY036118\":\"AY036118\", \"RPL9-PS6\":\"Rpl9-ps6\", \"RPS27\":\"Rps27\",\n",
    "    \"RPS4Y1\":\"RPS4Y1\", \"EIF1AY\":\"EIF1AY\", \"GNLY\":\"GNLY\", \"IFIT3\":\"IFIT3\", \"IFIT2\":\"IFIT2\", \n",
    "    \"RPS4X\":\"RPS4X\", \"RPL29\":\"RPL29\", \n",
    "    # Keep human gene names as-is since both datasets are human\n",
    "}\n",
    "\n",
    "# â”€â”€â”€ file paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DATA_DIR = \"/Users/haley/Desktop/send_tooo\"\n",
    "MLL_H5AD = os.path.join(DATA_DIR, \"human_2/mll_merged_qc.h5ad\")\n",
    "DONOR_H5AD = os.path.join(DATA_DIR, \"human_3/donor_merged_qc.h5ad\")\n",
    "OUT_DIR = pathlib.Path(\"/Users/haley/Downloads/CellSexID-main/result\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# â”€â”€â”€ helper functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def unify_gene_symbols(adata):\n",
    "    \"\"\"Normalize gene symbols using alias dictionary\"\"\"\n",
    "    if not isinstance(adata.var_names, pd.Index):\n",
    "        return adata\n",
    "    \n",
    "    # Create a mapping dictionary for renaming\n",
    "    rename_dict = {}\n",
    "    for gene in adata.var_names:\n",
    "        # Check for aliases (case insensitive)\n",
    "        gene_upper = gene.upper()\n",
    "        if gene_upper in alias_to_official:\n",
    "            rename_dict[gene] = alias_to_official[gene_upper]\n",
    "    \n",
    "    # Rename genes if aliases are found\n",
    "    if rename_dict:\n",
    "        print(f\"Renaming {len(rename_dict)} genes using alias dictionary\")\n",
    "        adata.var_names = [rename_dict.get(g, g) for g in adata.var_names]\n",
    "        \n",
    "    # Make variable names unique if needed\n",
    "    if not adata.var_names.is_unique:\n",
    "        print(\"Making gene names unique\")\n",
    "        adata.var_names_make_unique()\n",
    "        \n",
    "    return adata\n",
    "\n",
    "def extract_sex_labels(adata):\n",
    "    \"\"\"Extract standardized sex labels (0=female, 1=male)\"\"\"\n",
    "    if \"sex\" not in adata.obs:\n",
    "        raise ValueError(\"'sex' column not found in AnnData.\")\n",
    "\n",
    "    sex = (\n",
    "        adata.obs[\"sex\"]\n",
    "          .astype(str).str.strip().str.lower()\n",
    "          .map({\"female\": 0, \"male\": 1})\n",
    "    )\n",
    "    mask = sex.notna()\n",
    "    return adata[mask].copy(), sex[mask].astype(int).values\n",
    "\n",
    "def make_pipe(clf):\n",
    "    \"\"\"Create a preprocessing pipeline for a classifier\"\"\"\n",
    "    steps = [(\"imp\", SimpleImputer(strategy=\"median\"))]\n",
    "    if isinstance(clf, (LogisticRegression, SVC)):\n",
    "        steps.append((\"sc\", StandardScaler(with_mean=False)))\n",
    "    steps.append((\"clf\", clf))\n",
    "    return Pipeline(steps)\n",
    "\n",
    "def extract_marker_matrix(adata, markers):\n",
    "    \"\"\"Extract marker gene expression matrix from AnnData\"\"\"\n",
    "    # Convert var_names to lowercase for case-insensitive matching\n",
    "    var_lower = {g.lower(): g for g in adata.var_names}\n",
    "    \n",
    "    # Find markers present in dataset (case-insensitive)\n",
    "    present = [var_lower[g.lower()] for g in markers if g.lower() in var_lower]\n",
    "    \n",
    "    if len(present) < 2:\n",
    "        raise ValueError(f\"Fewer than 2 marker genes present in dataset. Found: {present}\")\n",
    "    \n",
    "    # Extract expression matrix as DataFrame\n",
    "    X_df = pd.DataFrame(\n",
    "        adata[:, present].X.A if sp.issparse(adata.X) else adata[:, present].X,\n",
    "        index=adata.obs_names,\n",
    "        columns=present,\n",
    "    )\n",
    "    \n",
    "    # Drop constant columns that don't provide information\n",
    "    nonconst = (X_df != X_df.iloc[0]).any()\n",
    "    if (~nonconst).any():\n",
    "        dropped = X_df.columns[~nonconst].tolist()\n",
    "        warnings.warn(f\"Dropping constant marker(s): {dropped}\")\n",
    "        X_df = X_df.loc[:, nonconst]\n",
    "        present = X_df.columns.tolist()\n",
    "    \n",
    "    if len(present) < 2:\n",
    "        raise ValueError(\"Need â‰¥2 informative markers after filtering.\")\n",
    "    \n",
    "    print(f\"Markers used ({len(present)}): {present}\")\n",
    "    \n",
    "    return X_df, present\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â• 1) Load datasets â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"Loading MLL dataset...\")\n",
    "mll_adata = sc.read_h5ad(MLL_H5AD)\n",
    "mll_adata = unify_gene_symbols(mll_adata)\n",
    "mll_adata, mll_y = extract_sex_labels(mll_adata)\n",
    "print(f\"MLL dataset: {mll_adata.n_obs:,} cells  \"\n",
    "      f\"(â™€ {(mll_y==0).sum()}  â™‚ {(mll_y==1).sum()})\")\n",
    "\n",
    "print(\"\\nLoading Donor dataset (test data)...\")\n",
    "test_adata = sc.read_h5ad(DONOR_H5AD)\n",
    "test_adata = unify_gene_symbols(test_adata)\n",
    "test_adata, y_test = extract_sex_labels(test_adata)\n",
    "print(f\"Donor dataset: {test_adata.n_obs:,} cells  \"\n",
    "      f\"(â™€ {(y_test==0).sum()}  â™‚ {(y_test==1).sum()})\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â• 2) Subsample MLL dataset (1/15) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\nExtracting 1/15 random subsample from MLL dataset...\")\n",
    "subsample_size = len(mll_adata) // 15\n",
    "\n",
    "indices = np.arange(len(mll_adata))\n",
    "_, subsample_indices, _, y_subsample = train_test_split(\n",
    "    indices, mll_y, test_size=subsample_size/len(mll_adata), \n",
    "    stratify=mll_y, random_state=42\n",
    ")\n",
    "\n",
    "# Create subsampled AnnData object for training\n",
    "train_adata = mll_adata[subsample_indices].copy()\n",
    "y_train = mll_y[subsample_indices]\n",
    "print(f\"Training subsample: {train_adata.n_obs:,} cells  \"\n",
    "      f\"(â™€ {(y_train==0).sum()}  â™‚ {(y_train==1).sum()})\")\n",
    "print(f\"Subsampling ratio: {train_adata.n_obs/mll_adata.n_obs:.1%} of original MLL data\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â• 3) Extract marker matrices â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\nExtracting selected marker genes from training data...\")\n",
    "X_train_df, train_markers = extract_marker_matrix(train_adata, SELECTED_MARKERS)\n",
    "\n",
    "print(\"\\nExtracting selected marker genes from test data...\")\n",
    "X_test_df, test_markers = extract_marker_matrix(test_adata, SELECTED_MARKERS)\n",
    "\n",
    "# Find common markers between train and test sets\n",
    "common_markers = sorted(set(train_markers) & set(test_markers))\n",
    "if len(common_markers) < 2:\n",
    "    raise ValueError(f\"Fewer than 2 common marker genes between datasets. Found: {common_markers}\")\n",
    "\n",
    "print(f\"\\nCommon markers used for training and testing ({len(common_markers)}): {common_markers}\")\n",
    "\n",
    "# Use only common markers\n",
    "X_train = X_train_df[common_markers].values\n",
    "X_test = X_test_df[common_markers].values\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â• 4) Define models â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "pipelines = {\n",
    "    \"LogisticRegression\": make_pipe(LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    \"LinearSVC\": make_pipe(SVC(kernel=\"linear\", probability=True, random_state=42)),\n",
    "    \"XGBoost\": make_pipe(XGBClassifier(\n",
    "        eval_metric=\"logloss\", random_state=42,\n",
    "        n_estimators=100, learning_rate=0.05, max_depth=10)),\n",
    "    \"RandomForest\": make_pipe(RandomForestClassifier(max_depth=10, random_state=42)),\n",
    "}\n",
    "\n",
    "# Set up for curve data collection and plotting\n",
    "curve_data_roc = []\n",
    "curve_data_pr = []\n",
    "colors = {\n",
    "    \"LogisticRegression\": \"blue\",\n",
    "    \"LinearSVC\": \"red\",\n",
    "    \"XGBoost\": \"green\",\n",
    "    \"RandomForest\": \"purple\"\n",
    "}\n",
    "\n",
    "# Create figures for plotting\n",
    "fig_roc, ax_roc = plt.subplots(figsize=(10, 8))\n",
    "fig_pr, ax_pr = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â• 5) Train and evaluate models â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training and evaluating models using selected genes\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results = []\n",
    "for name, model in pipelines.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 1) Train performance\n",
    "    p_tr = model.predict(X_train)\n",
    "    prob_tr = model.predict_proba(X_train)[:, 1]\n",
    "    tr_acc = accuracy_score(y_train, p_tr)\n",
    "    tr_f1 = f1_score(y_train, p_tr)\n",
    "    tr_roc = roc_auc_score(y_train, prob_tr)\n",
    "    tr_pr = average_precision_score(y_train, prob_tr)\n",
    "    print(f\" TRAIN â†’ Acc={tr_acc:.4f}, F1={tr_f1:.4f}, AUROC={tr_roc:.4f}, AUPRC={tr_pr:.4f}\")\n",
    "\n",
    "    # 2) Test performance\n",
    "    p_test = model.predict(X_test)\n",
    "    prob_test = model.predict_proba(X_test)[:, 1]\n",
    "    test_acc = accuracy_score(y_test, p_test)\n",
    "    test_f1 = f1_score(y_test, p_test)\n",
    "    test_roc = roc_auc_score(y_test, prob_test)\n",
    "    test_pr = average_precision_score(y_test, prob_test)\n",
    "    print(f\" TEST â†’ Acc={test_acc:.4f}, F1={test_f1:.4f}, AUROC={test_roc:.4f}, AUPRC={test_pr:.4f}\")\n",
    "    print(\"  Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, p_test))\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Train_Acc\": tr_acc, \"Train_F1\": tr_f1,\n",
    "        \"Train_AUROC\": tr_roc, \"Train_AUPRC\": tr_pr,\n",
    "        \"Test_Acc\": test_acc, \"Test_F1\": test_f1,\n",
    "        \"Test_AUROC\": test_roc, \"Test_AUPRC\": test_pr,\n",
    "    })\n",
    "    \n",
    "    # Calculate ROC curve points\n",
    "    fpr, tpr, _ = roc_curve(y_test, prob_test)\n",
    "    roc_df = pd.DataFrame({\"model\": name, \"fpr\": fpr, \"tpr\": tpr})\n",
    "    curve_data_roc.append(roc_df)\n",
    "    \n",
    "    # Calculate PR curve points\n",
    "    precision, recall, _ = precision_recall_curve(y_test, prob_test)\n",
    "    pr_df = pd.DataFrame({\"model\": name, \"precision\": precision, \"recall\": recall})\n",
    "    curve_data_pr.append(pr_df)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    ax_roc.plot(fpr, tpr, lw=2, color=colors[name], \n",
    "             label=f'{name} (area = {test_roc:.3f})')\n",
    "    \n",
    "    # Plot PR curve\n",
    "    ax_pr.plot(recall, precision, lw=2, color=colors[name], \n",
    "            label=f'{name} (area = {test_pr:.3f})')\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â• 6) Save results â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Combine and save curve data\n",
    "all_roc_data = pd.concat(curve_data_roc, ignore_index=True)\n",
    "all_pr_data = pd.concat(curve_data_pr, ignore_index=True)\n",
    "\n",
    "all_roc_data.to_csv(OUT_DIR / \"human2_to_human3_selected_auroc.csv\", index=False)\n",
    "all_pr_data.to_csv(OUT_DIR / \"human2_to_human3_selected_auprc.csv\", index=False)\n",
    "\n",
    "# Finalize and save ROC plot\n",
    "ax_roc.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "ax_roc.set_xlim([0.0, 1.0])\n",
    "ax_roc.set_ylim([0.0, 1.05])\n",
    "ax_roc.set_xlabel('False Positive Rate')\n",
    "ax_roc.set_ylabel('True Positive Rate')\n",
    "ax_roc.set_title('Human2 (MLL) â†’ Human3 (Donor): ROC Curves (Selected Genes)')\n",
    "ax_roc.legend(loc=\"lower right\")\n",
    "ax_roc.grid(True, linestyle='--', alpha=0.7)\n",
    "fig_roc.tight_layout()\n",
    "fig_roc.savefig(OUT_DIR / \"human2_to_human3_selected_roc_curves.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Finalize and save PR plot\n",
    "ax_pr.set_xlabel('Recall')\n",
    "ax_pr.set_ylabel('Precision')\n",
    "ax_pr.set_ylim([0.0, 1.05])\n",
    "ax_pr.set_xlim([0.0, 1.0])\n",
    "ax_pr.set_title('Human2 (MLL) â†’ Human3 (Donor): Precision-Recall Curves (Selected Genes)')\n",
    "ax_pr.legend(loc=\"lower left\")\n",
    "ax_pr.grid(True, linestyle='--', alpha=0.7)\n",
    "fig_pr.tight_layout()\n",
    "fig_pr.savefig(OUT_DIR / \"human2_to_human3_selected_pr_curves.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "# Save summary results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nFinal results:\")\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv(OUT_DIR / \"human2_to_human3_selected_summary_results.csv\", index=False)\n",
    "print(f\"\\nAll results saved to {OUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
